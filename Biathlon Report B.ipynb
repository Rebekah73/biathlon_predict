{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Table of Contents\n",
    "\n",
    "[Introduction](#Introduction)\n",
    "\n",
    "[Collecting the Data](#Collecting-data-by-racer)\n",
    "\n",
    "[Weighting the Races](#Weighting-the-Races)\n",
    "\n",
    "[Isolating Variable Effects](#isolating_variable_effects)\n",
    "\n",
    "[Pulling it all together](#pulling_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First a cell to prepare the notebook for the stuff that I might need to use. More imports\n",
    "# can be added as necessary. \n",
    "\n",
    "# A special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from pattern import web\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# And the additional modules that I've used\n",
    "\n",
    "import fnmatch\n",
    "import os\n",
    "import pickle\n",
    "from PyPDF2 import PdfFileReader\n",
    "from tabula import read_pdf\n",
    "import urllib\n",
    "import random\n",
    "import sklearn\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import joblib\n",
    "\n",
    "import matplotlib as mpl\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "My goal for this notebook is to take the data that I've collected in the previous notebook, and to explore the ability of each of our predictor variables to successfully produce a reasonable distribution of predictions for each of the pieces that constitute a sprint biathlon race. \n",
    "\n",
    "Next Section: [Collecting the Data](#Collecting-data-by-racer)\n",
    "\n",
    "[Table of Contents](#Table-of-Contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Collecting data by racer\n",
    "\n",
    "Above, I divide the the information about races into several pieces, each of which has different main influences. I hope to use this information to allow me to make some predictions about both racer times in future events and likely rankings. I hope to use this model to predict outcomes for the 2015-2016, 2016-2017, and 2017-2018 seasons, each time using only (and all) of the data from races that have previously occured. In order to accomplish this, I first will need to collate all of the various pieces (speed, missed shots, and range/penalty time) sorted by racer. In order to do this, I first need to correct some of the data that I have. In particular, those biathletes whose names contain accents or a written in a non Latin alphabet often have multiple spellings for their names. As a result, their spellings need to be made consistant in order to collect data over their entire careers. In order to do this, I systematically went through a list of all of the athletes that I had results for, looking for likely doubles, and checking them against the current (official) spellings used for each athlete by the International Biathlon Union. I then entered the data in an Excel spreadsheet (because it's sometimes better to see what you have), and stored it as a .csv file. From there, I used\n",
    "\n",
    "```replace_names```: this function takes a competition analysis dataframe and ensures that all of the given names are the official IBU versions of those names, corrects those that are not, and returns a fixed version of the dataframe.\n",
    "\n",
    "to replace the names. Next, I interleaved World Cup and IBU Cup races for the 14 seasons for which I had data, so that a biathlete who bounced back and forth between the two levels of competition for a season or two (not an unusual occurence, particularly for early career athletes) would have all of their events in the order in which they occured. I then used this list to loop through all of the ibu cup and world cup races in order of their occurence from the 2004-2005 season through the 2017-2018 season. The code for this can be found here:\n",
    "1. [Collecting the speed data](#Collecting-the-speed-data)\n",
    "2. [Collecting the accuracy data](#Collecting-the-accuracy-data)\n",
    "3. [Collecting the Range and Penalty Data](#Collecting-the-range-and-penalty-data)\n",
    "\n",
    "In each of these three cases, we loop through the events in chronological order, and use an outer merge on the name column to collect the relevent data into a dataframe or dataframes. The resulting dataframes are then pickled to allow them to be easily used in subsequent notebooks without redoing the above.\n",
    "\n",
    "Previous Section: [Introduction](#Introduction)\n",
    "\n",
    "\n",
    "Next Section: [Weighting the Races](#Weighting-the-Races)\n",
    "\n",
    "\n",
    "\n",
    "[Table of Contents](#Table-of-Contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_equivalences = pd.read_csv('name_equivalences.csv', encoding = 'utf8')\n",
    "name_equivalences.set_index('Name', inplace = True)\n",
    "name_changes = name_equivalences.to_dict('dict')['Unnamed: 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "replace_names : takes a competition analysis dataframe and ensures that all of the given \n",
    "                names are the official IBU versions of those names\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "df : a dataframe containing the (filtered) competition analysis data for a world cup or\n",
    "     ibu cup men's sprint race\n",
    "name_changes : a dictionary giving the correspondance between old versions of a racer's \n",
    "               name and current (IBU official) versions\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "df : the original dataframe, but with any old name versions replaced with current versions\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def replace_names(df, name_changes):\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i,'Name'] in name_changes:\n",
    "            df.loc[i,'Name'] = name_changes[df.loc[i,'Name']]\n",
    "            \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0405\n",
      "0506\n",
      "0607\n",
      "0708\n",
      "0809\n",
      "0910\n",
      "1011\n",
      "1112\n",
      "1213\n",
      "1314\n",
      "1415\n",
      "1516\n",
      "1617\n",
      "1718\n"
     ]
    }
   ],
   "source": [
    "# Fixing the names \n",
    "\n",
    "seasons = ['0405','0506','0607','0708','0809','0910',\n",
    "           '1011','1112','1213','1314','1415','1516','1617','1718']\n",
    "events = ['CP01','CP02','CP03','CP04','CP05','CP06','CP07','CP08','CP09','CH__','OG__']\n",
    "\n",
    "for season in seasons:\n",
    "    print season\n",
    "    for event in events:\n",
    "        filename = ('companal_SMSP_%(season)s_%(event)s.pkl' \n",
    "                        %{'season' : season, 'event' : event})\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_pickle(filename)\n",
    "            df = replace_names(df, name_changes)\n",
    "            df.to_pickle(filename)\n",
    "            \n",
    "        except: # race has no competition analysis file\n",
    "            pass\n",
    "\n",
    "        filename1 = 'ibu_SMSP_%(season)s_%(event)s.pkl' %{'season' : season, 'event' : event}\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_pickle(filename1)\n",
    "            df = replace_names(df, name_changes)\n",
    "            df.to_pickle(filename1)\n",
    "            \n",
    "        except: # race has no competition analysis file\n",
    "            pass\n",
    "\n",
    "        filename2 = 'ibu_SMSPS_%(season)s_%(event)s.pkl' %{'season' : season, 'event' : event}\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_pickle(filename2)\n",
    "            df = replace_names(df, name_changes)\n",
    "            df.to_pickle(filename2)\n",
    "            \n",
    "        except: # race has no competition analysis file\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Interleaving World Cup and IBU Cup races\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_0405 = [['ibu', 'CP01'], ['ibu', 'CP02'], ['companal', 'CP01'], ['companal', 'CP02'], \n",
    "               ['ibu', 'CP03'], ['companal', 'CP03'], ['ibu', 'CP04'], ['companal', 'CP04'], \n",
    "               ['ibu', 'CP05'], ['companal', 'CP05'], ['ibu', 'CP06'], ['companal', 'CP06'], \n",
    "               ['companal', 'CP07'], ['companal', 'CP08'], ['ibu', 'CH__'], \n",
    "               ['companal', 'CH__'], ['ibu', 'CP07'], ['ibu', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_0506 = [['companal', 'CP01'], ['ibu', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'], \n",
    "               ['ibu', 'CP03'], ['companal', 'CP03'], ['companal', 'CP04'], \n",
    "               ['companal', 'CP05'], ['ibu', 'CP04'], ['ibu', 'CP05'], ['companal', 'CP06'],\n",
    "               ['companal', 'OG__'], ['ibu', 'CH__'], ['companal', 'CP07'], ['ibu', 'CP06'], \n",
    "               ['companal', 'CP08'], ['ibu', 'CP07'], ['companal', 'CP09']]\n",
    "\n",
    "events_0607 = [['companal', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP01'], \n",
    "               ['companal', 'CP03'], ['ibu', 'CP02'], ['companal', 'CP04'], \n",
    "               ['companal', 'CP05'], ['ibu', 'CP03'], ['companal', 'CP06'], \n",
    "               ['ibu', 'CP04'], ['companal', 'CH__'], ['ibu', 'CP06'], ['ibu', 'CH__'],\n",
    "               ['companal', 'CP07'], ['companal', 'CP08'], ['ibu', 'CP07'], \n",
    "               ['companal', 'CP09'], ['ibu', 'CP08']]\n",
    "\n",
    "events_0708 = [['ibu', 'CP01'], ['companal', 'CP01'], ['ibu', 'CP02'], ['companal', 'CP02'],\n",
    "               ['ibu', 'CP03'], ['companal', 'CP03'], ['ibu', 'CP04'], ['companal', 'CP04'],\n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CP06'],\n",
    "               ['companal', 'CH__'], ['ibu', 'CH__'], ['companal', 'CP07'], \n",
    "               ['companal', 'CP08'], ['ibu', 'CP07'], ['companal', 'CP09'], ['ibu', 'CP08']]\n",
    "\n",
    "events_0809 = [['ibu', 'CP01'], ['companal', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'],\n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'],\n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CP06'], \n",
    "               ['companal', 'CH__'], ['ibu', 'CP07'], ['ibu', 'CH__'], ['companal', 'CP07'], \n",
    "               ['ibu', 'CP08'], ['companal', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_0910 = [['ibu', 'CP01'], ['companal', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'],\n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'],\n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CP06'],\n",
    "               ['ibu', 'CP07'], ['companal', 'OG__'], ['ibu', 'CH__'], ['companal', 'CP07'],\n",
    "               ['ibu', 'CP08'], ['companal', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1011 = [['ibu', 'CP01'], ['companal', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'],\n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'],\n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], \n",
    "               ['companal', 'CP07'], ['ibu', 'CP06'], ['companal', 'CP08'], ['ibu', 'CP07'], \n",
    "               ['ibu', 'CH__'], ['companal', 'CH__'], ['ibu', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1112 = [['ibu', 'CP01'], ['companal', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'],\n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'], \n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CH__'],\n",
    "               ['companal', 'CP07'], ['companal', 'CP08'], ['ibu', 'CP06'], ['ibu', 'CP07'], \n",
    "               ['companal', 'CH__'], ['ibu', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1213 = [['companal', 'CP01'], ['ibu', 'CP01'], ['ibu', 'CP02'], ['companal', 'CP02'], \n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'],\n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CP06'], \n",
    "               ['companal', 'CH__'], ['ibu', 'CP07'], ['ibu', 'CH__'], ['companal', 'CP07'],\n",
    "               ['companal', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1314 = [['companal', 'CP01'], ['ibu', 'CP01'], ['ibu', 'CP02'], ['companal', 'CP02'], \n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'],\n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CP06'],\n",
    "               ['ibu', 'CH__'], ['companal', 'OG__'], ['ibu', 'CP07'], ['companal', 'CP07'],\n",
    "               ['companal', 'CP08'], ['ibu', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1415 = [['companal', 'CP01'], ['ibu', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'],\n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'], \n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CH__'], \n",
    "               ['companal', 'CP07'], ['ibu', 'CP06'], ['companal', 'CP08'], ['ibu', 'CP07'], \n",
    "               ['companal', 'CH__'], ['ibu', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1516 = [['companal', 'CP01'], ['ibu', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'], \n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'], \n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CP06'], \n",
    "               ['companal', 'CP07'], ['companal', 'CP08'], ['ibu', 'CP07'], ['ibu', 'CH__'], \n",
    "               ['companal', 'CH__'], ['ibu', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1617 = [['companal', 'CP01'], ['ibu', 'CP01'], ['companal', 'CP02'], ['ibu', 'CP02'], \n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'], \n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CH__'], \n",
    "               ['ibu', 'CP06'], ['companal', 'CH__'], ['companal', 'CP07'], ['ibu', 'CP07'], \n",
    "               ['companal', 'CP08'], ['ibu', 'CP08'], ['companal', 'CP09']]\n",
    "\n",
    "events_1718 = [['ibu', 'CP01'], ['companal', 'CP01'], ['ibu', 'CP02'], ['companal', 'CP02'],\n",
    "               ['companal', 'CP03'], ['ibu', 'CP03'], ['companal', 'CP04'], ['ibu', 'CP04'],\n",
    "               ['companal', 'CP05'], ['ibu', 'CP05'], ['companal', 'CP06'], ['ibu', 'CH__'], \n",
    "               ['ibu', 'CP06'], ['companal', 'OG__'], ['companal', 'CP07'], ['ibu', 'CP07'],\n",
    "               ['companal', 'CP08'], ['ibu', 'CP08'], ['companal', 'CP09']              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_events ={'0405' : events_0405, '0506' : events_0506, '0607' : events_0607,\n",
    "                 '0708' : events_0708, '0809' : events_0809, '0910' : events_0910, \n",
    "                 '1011' : events_1011, '1112' : events_1112, '1213' : events_1213, \n",
    "                 '1314' : events_1314, '1415' : events_1415, '1516' : events_1516, \n",
    "                 '1617' : events_1617, '1718' : events_1718}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Collecting the speed data\n",
    "\n",
    "[Collecting data by racer](#Collecting-data-by-racer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0607 ['companal', 'CP08'] has no companal file\n",
      "0607 ['companal', 'CP09'] has no companal file\n",
      "0809 ['companal', 'CH__'] has no companal file\n",
      "1314 ['companal', 'CP05'] has no companal file\n",
      "1516 ['companal', 'CP05'] has no companal file\n",
      "1617 ['companal', 'CP06'] has no companal file\n",
      "1718 ['companal', 'CP05'] has no companal file\n"
     ]
    }
   ],
   "source": [
    "# And collecting the speed data\n",
    "\n",
    "absolute_mens_speed = pd.DataFrame(columns = ['Name'])\n",
    "\n",
    "seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "           '1516','1617','1718']\n",
    "\n",
    "for season in seasons:\n",
    "    events = ordered_events[season]\n",
    "    for event in events:\n",
    "        if event[0] == 'ibu':\n",
    "            filename1 = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            filename2 = ('%(cup)s_SMSPS_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "\n",
    "            colname1 = ':'.join(['ibu',season,event[1]])\n",
    "            colname2 = ':'.join(['ibuS',season,event[1]])\n",
    "            try:\n",
    "                df = pd.read_pickle(filename1)[['Name','Speed']]\n",
    "                df.columns = ['Name',colname1]\n",
    "                absolute_mens_speed = absolute_mens_speed.merge(df, how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "            try:\n",
    "                df = pd.read_pickle(filename2)[['Name','Speed']]\n",
    "                df.columns = ['Name',colname2]\n",
    "                absolute_mens_speed = absolute_mens_speed.merge(df, how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "        else:\n",
    "            filename = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                            %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            colname = ':'.join(['wc',season,event[1]])\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_pickle(filename)[['Name','Speed']]\n",
    "                df.columns = ['Name',colname]\n",
    "                absolute_mens_speed = absolute_mens_speed.merge(df, how = 'outer', on = 'Name')\n",
    "            \n",
    "            except:\n",
    "                print season, event, 'has no companal file'\n",
    "\n",
    "last_row = len(absolute_mens_speed)\n",
    "\n",
    "for col in absolute_mens_speed.columns.tolist():\n",
    "    absolute_mens_speed.loc[last_row, col] = \"\".join(['20', col[2:4]])\n",
    "    \n",
    "for i in range(len(absolute_mens_speed)):\n",
    "    absolute_mens_speed.loc[i,'count'] = absolute_mens_speed.loc[i].count() - 1\n",
    "    \n",
    "absolute_mens_speed.loc[last_row,'Name'] = 'Year'\n",
    "\n",
    "absolute_mens_speed.set_index('Name', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the interest of not having to do this again, let's pickle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "absolute_mens_speed.to_pickle('absolute_mens_speed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Collecting the accuracy data\n",
    "\n",
    "[Collecting data by racer](#Collecting-data-by-racer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collecting the prone accuracy data\n",
    "\n",
    "absolute_mens_prone_shooting = pd.DataFrame(columns = ['Name'])\n",
    "\n",
    "seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "           '1516','1617','1718']\n",
    "\n",
    "for season in seasons:\n",
    "    events = ordered_events[season]\n",
    "    for event in events:\n",
    "        if event[0] == 'ibu':\n",
    "            filename1 = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            filename2 = ('%(cup)s_SMSPS_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "\n",
    "            colname1 = ':'.join(['ibu',season,event[1]])\n",
    "            colname2 = ':'.join(['ibuS',season,event[1]])\n",
    "            try:\n",
    "                df = pd.read_pickle(filename1)[['Name','P1']]\n",
    "                df.columns = ['Name',colname1]\n",
    "                absolute_mens_prone_shooting = absolute_mens_prone_shooting.merge(df, \n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "            try:\n",
    "                df = pd.read_pickle(filename2)[['Name','P1']]\n",
    "                df.columns = ['Name',colname2]\n",
    "                absolute_mens_prone_shooting = absolute_mens_prone_shooting.merge(df, \n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "        else:\n",
    "            filename = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                            %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            colname = ':'.join(['wc',season,event[1]])\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_pickle(filename)[['Name','P1']]\n",
    "                df.columns = ['Name',colname]\n",
    "                absolute_mens_prone_shooting = absolute_mens_prone_shooting.merge(df,\n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "\n",
    "last_row = len(absolute_mens_prone_shooting)\n",
    "\n",
    "for col in absolute_mens_prone_shooting.columns.tolist():\n",
    "    absolute_mens_prone_shooting.loc[last_row, col] = \"\".join(['20', col[2:4]])\n",
    "    \n",
    "for i in range(len(absolute_mens_prone_shooting)):\n",
    "    absolute_mens_prone_shooting.loc[i,'count'] = \\\n",
    "                                    absolute_mens_prone_shooting.loc[i].count() - 1    \n",
    "absolute_mens_prone_shooting.loc[last_row,'Name'] = 'Year'\n",
    "\n",
    "absolute_mens_prone_shooting.set_index('Name', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collecting the standing accuracy data\n",
    "\n",
    "absolute_mens_standing_shooting = pd.DataFrame(columns = ['Name'])\n",
    "\n",
    "seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "           '1516','1617','1718']\n",
    "\n",
    "for season in seasons:\n",
    "    events = ordered_events[season]\n",
    "    for event in events:\n",
    "        if event[0] == 'ibu':\n",
    "            filename1 = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            filename2 = ('%(cup)s_SMSPS_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "\n",
    "            colname1 = ':'.join(['ibu',season,event[1]])\n",
    "            colname2 = ':'.join(['ibuS',season,event[1]])\n",
    "            try:\n",
    "                df = pd.read_pickle(filename1)[['Name','S1']]\n",
    "                df.columns = ['Name',colname1]\n",
    "                absolute_mens_standing_shooting = absolute_mens_standing_shooting.merge(df, \n",
    "                                                                 how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "            try:\n",
    "                df = pd.read_pickle(filename2)[['Name','S1']]\n",
    "                df.columns = ['Name',colname2]\n",
    "                absolute_mens_standing_shooting = absolute_mens_standing_shooting.merge(df,\n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "        else:\n",
    "            filename = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                            %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            colname = ':'.join(['wc',season,event[1]])\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_pickle(filename)[['Name','S1']]\n",
    "                df.columns = ['Name',colname]\n",
    "                absolute_mens_standing_shooting = absolute_mens_standing_shooting.merge(df, \n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "\n",
    "last_row = len(absolute_mens_standing_shooting)\n",
    "\n",
    "for col in absolute_mens_standing_shooting.columns.tolist():\n",
    "    absolute_mens_standing_shooting.loc[last_row, col] = \"\".join(['20', col[2:4]])\n",
    "    \n",
    "for i in range(len(absolute_mens_standing_shooting)):\n",
    "    absolute_mens_standing_shooting.loc[i,'count'] = \\\n",
    "                                        absolute_mens_standing_shooting.loc[i].count() - 1\n",
    "    \n",
    "absolute_mens_standing_shooting.loc[last_row,'Name'] = 'Year'\n",
    "\n",
    "absolute_mens_standing_shooting.set_index('Name', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then to pickle them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "absolute_mens_prone_shooting.to_pickle('absolute_mens_prone_shooting.pkl')\n",
    "absolute_mens_standing_shooting.to_pickle('absolute_mens_standing_shooting.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the range and penalty data\n",
    "\n",
    "[Collecting data by racer](#Collecting-data-by-racer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collecting the prone range data (Note: this includes penalty loop times for prone shooting)\n",
    "\n",
    "absolute_mens_prone_range = pd.DataFrame(columns = ['Name'])\n",
    "\n",
    "seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "           '1516','1617','1718']\n",
    "\n",
    "for season in seasons:\n",
    "    events = ordered_events[season]\n",
    "    for event in events:\n",
    "        if event[0] == 'ibu':\n",
    "            filename1 = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            filename2 = ('%(cup)s_SMSPS_%(season)s_%(event)s.pkl' \n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "\n",
    "            colname1 = ':'.join(['ibu',season,event[1]])\n",
    "            colname2 = ':'.join(['ibuS',season,event[1]])\n",
    "            try:\n",
    "                df = pd.read_pickle(filename1)[['Name','prone range']]\n",
    "                df.columns = ['Name',colname1]\n",
    "                absolute_mens_prone_range = absolute_mens_prone_range.merge(df,\n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "            try:\n",
    "                df = pd.read_pickle(filename2)[['Name','prone range']]\n",
    "                df.columns = ['Name',colname2]\n",
    "                absolute_mens_prone_range = absolute_mens_prone_range.merge(df, \n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "        else:\n",
    "            filename = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                            %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            colname = ':'.join(['wc',season,event[1]])\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_pickle(filename)[['Name','prone range']]\n",
    "                df.columns = ['Name',colname]\n",
    "                absolute_mens_prone_range = absolute_mens_prone_range.merge(df, \n",
    "                                                                how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "\n",
    "last_row = len(absolute_mens_prone_range)\n",
    "\n",
    "for col in absolute_mens_prone_range.columns.tolist():\n",
    "    absolute_mens_prone_range.loc[last_row, col] = \"\".join(['20', col[2:4]])\n",
    "    \n",
    "for i in range(len(absolute_mens_prone_range)):\n",
    "    absolute_mens_prone_range.loc[i,'count'] = absolute_mens_prone_range.loc[i].count() - 1\n",
    "    \n",
    "absolute_mens_prone_range.loc[last_row,'Name'] = 'Year'\n",
    "\n",
    "absolute_mens_prone_range.set_index('Name', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collecting the standing range times (including penalties)\n",
    "\n",
    "absolute_mens_standing_range = pd.DataFrame(columns = ['Name'])\n",
    "\n",
    "seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "           '1516','1617','1718']\n",
    "\n",
    "for season in seasons:\n",
    "    events = ordered_events[season]\n",
    "    for event in events:\n",
    "        if event[0] == 'ibu':\n",
    "            filename1 = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl'\n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            filename2 = ('%(cup)s_SMSPS_%(season)s_%(event)s.pkl'\n",
    "                             %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "\n",
    "            colname1 = ':'.join(['ibu',season,event[1]])\n",
    "            colname2 = ':'.join(['ibuS',season,event[1]])\n",
    "            try:\n",
    "                df = pd.read_pickle(filename1)[['Name','standing range']]\n",
    "                df.columns = ['Name',colname1]\n",
    "                absolute_mens_standing_range = absolute_mens_standing_range.merge(df, \n",
    "                                                                    how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "            try:\n",
    "                df = pd.read_pickle(filename2)[['Name','standing range']]\n",
    "                df.columns = ['Name',colname2]\n",
    "                absolute_mens_standing_range = absolute_mens_standing_range.merge(df, \n",
    "                                                                    how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "        else:\n",
    "            filename = ('%(cup)s_SMSP_%(season)s_%(event)s.pkl' \n",
    "                            %{'cup' : event[0], 'season' : season, 'event' : event[1]})\n",
    "            colname = ':'.join(['wc',season,event[1]])\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_pickle(filename)[['Name','standing range']]\n",
    "                df.columns = ['Name',colname]\n",
    "                absolute_mens_standing_range = absolute_mens_standing_range.merge(df, \n",
    "                                                                    how = 'outer', on = 'Name')\n",
    "            \n",
    "            except: # race has no competition analysis file\n",
    "                pass\n",
    "\n",
    "last_row = len(absolute_mens_standing_range)\n",
    "\n",
    "for col in absolute_mens_standing_range.columns.tolist():\n",
    "    absolute_mens_standing_range.loc[last_row, col] = \"\".join(['20', col[2:4]])\n",
    "    \n",
    "for i in range(len(absolute_mens_standing_range)):\n",
    "    absolute_mens_standing_range.loc[i,'count'] = \\\n",
    "                                             absolute_mens_standing_range.loc[i].count() - 1    \n",
    "absolute_mens_standing_range.loc[last_row,'Name'] = 'Year'\n",
    "\n",
    "absolute_mens_standing_range.set_index('Name', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to pickle them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "absolute_mens_prone_range.to_pickle('absolute_mens_prone_range.pkl')\n",
    "absolute_mens_standing_range.to_pickle('absolute_mens_standing_range.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"WeightingtheRaces\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Weighting the Races \n",
    "\n",
    "One of the most important uses of the investigations above on the impacts of season, event, etc on attributes such as penalty loop times, speed, etc, is to hopefully allow us to more accurately predict outcomes for both total times for individual racers in a particular race, and, perhaps more usefully, to predict how racers are likely to fare relative to each other. In order to accomplish this, however, I need to have some way of determining whether, say the third event of the 2016-2017 season is more similar to the third event of the 2015-2016 season or to the fifth event of the 2012-2013 season. Furthermore, given the dependencies that I found above, it seems as if we may need several different similarity values, one for each of the pieces of the puzzle that we want to put together : speed, prone accuracy, standing accuracy, prone range time, standing range time, prone penalty loop time, and standing penalty loop time.\n",
    "\n",
    "We start by, for each predictor variable, creating a dataframe of size $n \\times n$, where $n$ is the number of races that we have data for, such that the entry in row i and column j is the difference in values of the predictor variable between races i and j.\n",
    "\n",
    "In order to do this, I use the following functions:\n",
    "1. ```course_similarities```: this function cycles through all pairings of events in a pair of world cup seasons (possibly the same), and determines the absolute value of the differences of the values of the given predictor variable for those two competitions. Here we restrict to variables that describe the course itself: 'Length', 'Height Diff', 'Max Climb', 'Total Climb', 'Altitude', 'Quant Year', and 'Quant Event'\n",
    "2. ```course_similarities_pred```: cycles through all pairs of world cup seasons for a given course predictor and applies ```course_similarities``` for each pairing. It then divides the differences found by the total change in values for that variable, taken over all seasons, and rounds the obtained values to the nearest tenth. These values are then combined into a single dataframe which is returned by the function.\n",
    "3. ```ibu_course_similarities```: this function is the equivalent of ```course_similarities```, except that rather than finding similarities between two world cup seasons, it finds similarities between one world cup season and one ibu cup season.\n",
    "4. ```ibu_course_similarities_pred```: this function is the equivalent of ```course_similarities_pred``` except that, rather than run through all pairings of two world cup seasons, it runs through all pairings of one world cup season and one ibu cup season.\n",
    "5. ```condition_similarities```: this function is the equivalent of ```course_similarities```, except that rather than restricting to variables describing the course, we restrict to variables describing the (weather) conditions: 'Air Temp C', 'Snow Temp C', 'Wind C', 'Humidity C', 'Quant Weather', 'Humidity C', 'Quant Weather', and 'Quant Snow'\n",
    "2. ```condition_similarities_pred```: this function is the equivalent of ```course_similarities_pred```, except that it applies ```condition_similarities``` for each season pairing rather than ```course_similarities``` \n",
    "3. ```ibu_condition_similarities```: this function is the equivalent to ```condition_similarities```, except that rather than finding similarities between two world cup seasons, it finds similarities between one world cup season and one ibu cup season.\n",
    "4. ```ibu_condition_similarities_pred```: this function is the equivalent of ```condition_similarites_pred```, except that, rather than run through all pairings of two world cup seasons, it runs through all pairings of one world cup season and one ibu season.\n",
    "\n",
    "Previous Section: [Collecting the Data](#Collecting-data-by-racer)\n",
    "\n",
    "Next Section: [Isolating Variable Effects](#isolating_variable_effects)\n",
    "\n",
    "[Table of Contents](#Table-of-Contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_conditions = pd.read_pickle('weather_averages.pkl')\n",
    "snow_conditions = pd.read_pickle('snow_averages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "           '1516','1617','1718']\n",
    "\n",
    "for season in seasons:\n",
    "    filename = 'weather_summary_%(season)s_M.pkl' %{'season' : season}\n",
    "    df = pd.read_pickle(filename)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        df.loc[i,'Quant Weather'] = weather_conditions.loc[df.loc[i,'Weather C'], \n",
    "                                                                           'Weather Quant']\n",
    "        df.loc[i, 'Quant Snow'] = snow_conditions.loc[df.loc[i, 'Snow Cond C'], 'Snow Quant']\n",
    "        \n",
    "    df.to_pickle(filename)\n",
    "    \n",
    "for season in seasons:\n",
    "    filename1 = 'ibu_weather_summary_%(season)s_M.pkl' %{'season' : season}\n",
    "    df1 = pd.read_pickle(filename1)\n",
    "    \n",
    "    for i in range(len(df1)):\n",
    "        df1.loc[i,'Quant Weather'] = weather_conditions.loc[df1.loc[i,'Weather C'], \n",
    "                                                                            'Weather Quant']\n",
    "        df1.loc[i, 'Quant Snow'] = snow_conditions.loc[df1.loc[i, 'Snow Cond C'], \n",
    "                                                                               'Snow Quant']\n",
    "        \n",
    "    df1.to_pickle(filename1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "course_similarities : cycles through all pairings of events in a pair of seasons (possibly\n",
    "                      the same), and determines the differences in the values \n",
    "                      taken by a given predictor variable for those two competitions\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "season1 : a string that codes one season under consideration. It is of the form y1y2 where\n",
    "          y1 is the last two digits of the year in which the season started, and y2 is the \n",
    "          last two digits of the year in which the season ended.\n",
    "season2 : a string that codes the other season under consideration. It is of the form y1y2\n",
    "          where y1 is the last two digits of the year in which the season started, and y2\n",
    "          is the last two digits of the year in which the season ended.\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Length', 'Height Diff','Max Climb','Total Climb',\n",
    "            'Altitude','Quant Year', and 'Quant Event'\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "similarities : a dataframe containing all of the season1 world cup events as rows and season2\n",
    "               world cup events as columns. The entries are the absolute values of the \n",
    "               differences between the predictor variable values for the two events.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def course_similarities(season1, season2, predictor):\n",
    "    \n",
    "    filename1 = 'course_summary_%(season1)s_M.pkl' %{'season1' : season1}\n",
    "    filename2 = 'course_summary_%(season2)s_M.pkl' %{'season2' : season2}\n",
    "    \n",
    "    df1 = pd.read_pickle(filename1)[['Year','Event',predictor]]\n",
    "    df2 = pd.read_pickle(filename2)[['Year','Event',predictor]]\n",
    "    \n",
    "    similarities = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df1)):\n",
    "        rowname = ':'.join([season1,df1.loc[i,'Event']])\n",
    "        for j in range(len(df2)):\n",
    "            colname = ':'.join([season2,df2.loc[j,'Event']])\n",
    "            similarities.loc[rowname,colname] = abs(float(df1.loc[i,predictor]) - \n",
    "                                                            float(df2.loc[j,predictor]))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "course_similarities_pred : cycles through all pairs of seasons for a given predictor and\n",
    "                           applies course_similarities for each pairing of world cup seasons,\n",
    "                           then converts them to a fraction of the total range taken by\n",
    "                           the given predictor, and concatenates all of the results into a \n",
    "                           dataframe\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Length', 'Height Diff','Max Climb','Total Climb',\n",
    "            'Altitude','Quant Year', and 'Quant Event'\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "stores a pickled dataframe on the hard drive\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def course_similarities_pred(predictor):\n",
    "    \n",
    "    seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "               '1516','1617','1718']\n",
    "\n",
    "    wc_course_similarities = pd.DataFrame()\n",
    "\n",
    "    for season1 in seasons:\n",
    "        similarities = pd.DataFrame()\n",
    "        for season2 in seasons:\n",
    "            two_season_similarites = course_similarities(season1, season2, predictor)\n",
    "            similarities = similarities.join(two_season_similarites, how='outer')\n",
    "        wc_course_similarities = pd.concat([wc_course_similarities, similarities])\n",
    "    \n",
    "    max_value = np.max(np.array(wc_course_similarities))\n",
    "\n",
    "    wc_course_similarities = (max_value - wc_course_similarities)/max_value\n",
    "    \n",
    "    filename = 'wc_%(pred)s_similarities.pkl' %{'pred' : predictor.lower().replace(\" \", \"_\")}\n",
    "    wc_course_similarities.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "ibu_course_similarities : cycles through all pairings of events in one world cup season \n",
    "                          and one ibu cup season (possibly the same years), and determines\n",
    "                          the differences in the values taken by a given predictor variable \n",
    "                          for those two competitions\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "season1 : a string that codes the world cup season under consideration. It is of the form \n",
    "          y1y2 where y1 is the last two digits of the year in which the season started, \n",
    "          and y2 is the last two digits of the year in which the season ended.\n",
    "season2 : a string that codes the ibu cup season under consideration. It is of the form y1y2\n",
    "          where y1 is the last two digits of the year in which the season started, and y2\n",
    "          is the last two digits of the year in which the season ended.\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Length', 'Height Diff','Max Climb','Total Climb',\n",
    "            'Altitude','Quant Year', and 'Quant Event'\n",
    "\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "similarities : a dataframe containing all of the season1 world cup events as rows and season2\n",
    "               ibu cup events as columns. The entries are the absolute values of the \n",
    "               differences between the predictor variable values for the two events.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "# Note that this puts the ibu events as the columns and world cup events as the rows, since\n",
    "# I'm interested in making predictions about world cup times\n",
    "\n",
    "def ibu_course_similarities(season1, season2, predictor):\n",
    "    \n",
    "    filename1 = 'course_summary_%(season1)s_M.pkl' %{'season1' : season1}\n",
    "    filename2 = 'ibu_course_summary_%(season2)s_M.pkl' %{'season2' : season2}\n",
    "    \n",
    "    df1 = pd.read_pickle(filename1)[['Year','Event',predictor]]\n",
    "    df2 = pd.read_pickle(filename2)[['Year','Event','Race',predictor]]\n",
    "    similarities = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df1)):\n",
    "        rowname = ':'.join([season1,df1.loc[i,'Event']])\n",
    "        for j in range(len(df2)):\n",
    "            if df2.loc[j,'Race'] == 'SMSP':\n",
    "                colname = ':'.join([season2,df2.loc[j,'Event']])\n",
    "            else:\n",
    "                colname = ':'.join([season2,\"\".join([df2.loc[j,'Event'],'S'])])\n",
    "            similarities.loc[rowname,colname] = abs(float(df1.loc[i,predictor]) - \n",
    "                                                                float(df2.loc[j,predictor]))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "ibu_course_similarities_pred : cycles through all pairings of one world cup season and one \n",
    "                               ibu cup season, applies course_similarities with the given \n",
    "                               predictor for each pairing, then converts them to a fraction\n",
    "                               of the total range taken by the given predictor, and \n",
    "                               concatenates all of the results into a dataframe\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Length', 'Height Diff','Max Climb','Total Climb',\n",
    "            'Altitude','Quant Year', and 'Quant Event'\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "saves a pickled dataframe on the hard drive\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def ibu_course_similarities_pred(predictor):\n",
    "    \n",
    "    seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "               '1516','1617','1718']\n",
    "\n",
    "    ibu_course_sims = pd.DataFrame()\n",
    "\n",
    "    for season1 in seasons:\n",
    "        similarities = pd.DataFrame()\n",
    "        for season2 in seasons:\n",
    "            two_season_similarites = ibu_course_similarities(season1, season2, predictor)\n",
    "            similarities = similarities.join(two_season_similarites, how='outer')\n",
    "        ibu_course_sims = pd.concat([ibu_course_sims, similarities])\n",
    "    \n",
    "    max_value = np.max(np.array(ibu_course_sims))\n",
    "\n",
    "    ibu_course_sims = (max_value - ibu_course_sims)/max_value\n",
    "    \n",
    "    filename = 'ibu_%(pred)s_similarities.pkl' %{'pred' : predictor.lower().replace(\" \", \"_\")}\n",
    "    ibu_course_sims.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = ['Length', 'Height Diff','Max Climb','Total Climb','Altitude','Quant Year',\n",
    "              'Quant Event']\n",
    "\n",
    "for predictor in predictors:\n",
    "    course_similarities_pred(predictor)\n",
    "    ibu_course_similarities_pred(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "condition_similarities : cycles through all pairings of events in two world cup seasons\n",
    "                         (possibly the same years), and determines the differences in the\n",
    "                         values taken by a given predictor variable for those two competitions\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "season1 : a string that codes one world cup season under consideration. It is of the form \n",
    "          y1y2 where y1 is the last two digits of the year in which the season started, \n",
    "          and y2 is the last two digits of the year in which the season ended.\n",
    "season2 : a string that codes another world cup season under consideration. It is of\n",
    "          the form y1y2 where y1 is the last two digits of the year in which the season \n",
    "          started, and y2 is the last two digits of the year in which the season ended.\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Air Temp C','Snow Temp C','Wind C','Humidity C',\n",
    "            'Quant Weather', 'Humidity C', 'Quant Weather', and 'Quant Snow'\n",
    "\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "similarities : a dataframe containing all of the season1 world cup events as rows and season2\n",
    "               world cup events as columns. The entries are the absolute values of the \n",
    "               differences between the predictor variable values for the two events.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def condition_similarities(season1, season2, predictor):\n",
    "    \n",
    "    filename1 = 'weather_summary_%(season1)s_M.pkl' %{'season1' : season1}\n",
    "    filename2 = 'weather_summary_%(season2)s_M.pkl' %{'season2' : season2}\n",
    "    \n",
    "    df1 = pd.read_pickle(filename1)[['Year','Event',predictor]]\n",
    "    df2 = pd.read_pickle(filename2)[['Year','Event',predictor]]\n",
    "    \n",
    "    similarities = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df1)):\n",
    "        rowname = ':'.join([season1,df1.loc[i,'Event']])\n",
    "        for j in range(len(df2)):\n",
    "            colname = ':'.join([season2,df2.loc[j,'Event']])\n",
    "            similarities.loc[rowname,colname] = abs(float(df1.loc[i,predictor]) - \n",
    "                                                            float(df2.loc[j,predictor]))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "condition_similarities_pred : cycles through all pairings of two world cup seasons, applies\n",
    "                              course_similarities with the given predictor for each pairing,\n",
    "                              then converts them to a fraction of the total range taken by \n",
    "                              the given predictor, and concatenates all of the results into\n",
    "                              a dataframe\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Air Temp C','Snow Temp C','Wind C','Humidity C',\n",
    "            'Quant Weather', 'Humidity C', 'Quant Weather', and 'Quant Snow'\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "stores a pickled dataframe on the hard drive\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def condition_similarities_pred(predictor):\n",
    "    seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415','1516','1617','1718']\n",
    "\n",
    "    wc_condition_sims = pd.DataFrame()\n",
    "\n",
    "    for season1 in seasons:\n",
    "        similarities = pd.DataFrame()\n",
    "        for season2 in seasons:\n",
    "            two_season_similarites = condition_similarities(season1, season2, predictor)\n",
    "            similarities = similarities.join(two_season_similarites, how='outer')\n",
    "        wc_condition_sims = pd.concat([wc_condition_sims, similarities])\n",
    "    \n",
    "    max_value = np.max(np.array(wc_condition_sims))\n",
    "\n",
    "    wc_condition_sims = (max_value - wc_condition_sims)/max_value\n",
    "    \n",
    "    filename = 'wc_%(pred)s_similarities.pkl' %{'pred' : predictor.lower().replace(\" \", \"_\")}\n",
    "    wc_condition_sims.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "ibu_condition_similarities : cycles through all pairings of events in one world cup season \n",
    "                             and one ibu cup season (possibly the same years), and determines\n",
    "                             the differences in the values taken by a given predictor variable \n",
    "                             for those two competitions\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "season1 : a string that codes the world cup season under consideration. It is of the form \n",
    "          y1y2 where y1 is the last two digits of the year in which the season started, \n",
    "          and y2 is the last two digits of the year in which the season ended.\n",
    "season2 : a string that codes the ibu cup season under consideration. It is of\n",
    "          the form y1y2 where y1 is the last two digits of the year in which the season \n",
    "          started, and y2 is the last two digits of the year in which the season ended.\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Air Temp C','Snow Temp C','Wind C','Humidity C',\n",
    "            'Quant Weather', 'Humidity C', 'Quant Weather', and 'Quant Snow'\n",
    "\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "similarities : a dataframe containing all of the season1 world cup events as rows and season2\n",
    "               ibu cup events as columns. The entries are the absolute values of the \n",
    "               differences between the predictor variable values for the two events.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def ibu_condition_similarities(season1, season2, predictor):\n",
    "    \n",
    "    filename1 = 'weather_summary_%(season1)s_M.pkl' %{'season1' : season1}\n",
    "    filename2 = 'ibu_weather_summary_%(season2)s_M.pkl' %{'season2' : season2}\n",
    "    \n",
    "    df1 = pd.read_pickle(filename1)[['Year','Event',predictor]]\n",
    "    df2 = pd.read_pickle(filename2)[['Year','Event','Race',predictor]]\n",
    "    \n",
    "    similarities = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df1)):\n",
    "        rowname = ':'.join([season1,df1.loc[i,'Event']])\n",
    "        for j in range(len(df2)):\n",
    "            if df2.loc[j,'Race'] == 'SMSP':\n",
    "                colname = ':'.join([season2,df2.loc[j,'Event']])\n",
    "            else:\n",
    "                colname = ':'.join([season2,\"\".join([df2.loc[j,'Event'],'S'])])\n",
    "            similarities.loc[rowname,colname] = abs(float(df1.loc[i,predictor]) - \n",
    "                                                            float(df2.loc[j,predictor]))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "ibu_condition_similarities_pred : cycles through all pairings of one world cup season and \n",
    "                                  one ibu cup season, applies course_similarities with the\n",
    "                                  given predictor for each pairing, then converts them to\n",
    "                                  a fraction of the total range taken by the given predictor,\n",
    "                                  and concatenates all of the results into a dataframe\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "predictor : one of the pieces of information about the courses for which we have data. \n",
    "            Possibilities include 'Air Temp C','Snow Temp C','Wind C','Humidity C',\n",
    "            'Quant Weather', 'Humidity C', 'Quant Weather', and 'Quant Snow'\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "saves a pickled dataframe to the hard drive\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def ibu_condition_similarities_pred(predictor):\n",
    "    seasons = ['0405','0506','0607','0708','0809','0910','1011','1112','1213','1314','1415',\n",
    "               '1516','1617','1718']\n",
    "\n",
    "    ibu_condition_sims = pd.DataFrame()\n",
    "\n",
    "    for season1 in seasons:\n",
    "        similarities = pd.DataFrame()\n",
    "        for season2 in seasons:\n",
    "            two_season_similarites = ibu_condition_similarities(season1, season2, predictor)\n",
    "            similarities = similarities.join(two_season_similarites, how='outer')\n",
    "        ibu_condition_sims = pd.concat([ibu_condition_sims, similarities])\n",
    "    \n",
    "    max_value = np.max(np.array(ibu_condition_sims))\n",
    "\n",
    "    ibu_condition_sims = (max_value - ibu_condition_sims)/max_value\n",
    "    \n",
    "    filename = 'ibu_%(pred)s_similarities.pkl' %{'pred' : predictor.lower().replace(\" \", \"_\")}\n",
    "    ibu_condition_sims.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = ['Air Temp C','Snow Temp C','Wind C','Humidity C','Quant Weather',\n",
    "              'Humidity C', 'Quant Weather', 'Quant Snow']\n",
    "\n",
    "for predictor in predictors:\n",
    "    condition_similarities_pred(predictor)\n",
    "    ibu_condition_similarities_pred(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"isolating_variable_effects\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolating the Variable Effects\n",
    "\n",
    "\n",
    "So, I think that much of the stuff below here is actually garbage, and I'll end up deleting it (and if for some reason, that's wrong, that's why I made a copy of the file.... One of the things that I did at the end was to try to isolate each individual predictor and see what effect weighting by only that predictor had on the predictive accuracy of my model. So, in order to do that, I need a random set of races to draw from, and I think that, since I want to make predictions about the last four seasons, that I want to use the first 10 seasons for testing. Furthermore, since my predictions are heavily dependant on a racer's performance in his previous races, I want to avoid randomly sampling from the first 5 seasons. And I think that 10 races for comparison are probably sufficient. I'm then going to consider each of the pieces of the total time separately. We have the following functions:\n",
    "\n",
    "- [Variable Effects on Speed](#Variable-Effects-on-Speed)\n",
    "    1. ```adjust_times```: Given a racer and a competition, this function takes his event speeds over all previous seasons in his career, finds the best fit line through the data (with ```quant_season``` as the predictor variable and ```speed``` as the response variable), and adjusts speeds from prior seasons to reflect what they would be predicted to be were the race run in the season under consideration.\n",
    "    2. ```build_racer_speed_distribution```: Given a racer, season, and event as well as dataframes containing similarity data about world cup vs world cup and world cup vs ibu cup race conditions, this function creates a list of speeds from previous races, in which the multiplicity of the speed is determined by the degree of similarity between the race of interest and the race from which the speed was taken. It then returns a list containing the racer's name, the mean of the list of speeds, the standard deviation of the list, the 10th, 25th, 50th, 75th, and 90th percentiles, the racer's actual speed, and the number of prior races in which the racer had competed.\n",
    "    3. ```check_predictions```: This function takes as input a dataframe created by concatenating the output of repeated calls to ```build_racer_*_distribution```. It returns a dataframe with one row for each racer which indicates whether or not that racer's actual *-value falls within the middle 50 percent and the middle 80 percent of the distributions obtained.\n",
    "    4. ```inside_outside```: This function takes a dataframe output by ```check_predictions``` and returns the percentage of racers whose actual *-values fall within the middle 50 percent of their time distributions. \n",
    "    5. ```above_below```: This function takes as input a dataframe created by concatenating the output of repeated calls to ```build_racer_*_distribution```. For each racer, it then determines whether or not that racer's actual *-value was above the mean of their distribution or not. The function then returns the percentage of racers for which this is true.\n",
    "    6. ```evaluate_variable_impact```: This function pulls together ```build_racer_speed_distribution```, ```check_predictions```, ```inside_outside```, and ```above_below```. Given a competition (season and event) and a predictor variable, it calculates the percentage of racers whose actual times were within the middle 50% of their distributions and the percentage of racers whose actual times were above the mean of their distributions and returns the results in the form of a list.\n",
    "    7. ```variable_score```: This function takes as input a dataframe produced by concatenating the results of repeated calls to ```evaluate_variable_impact```. It then sorts the dataframe event by event, assigning one point for the first place variable, two for the second place variable, etc as it goes. It then sums these values for each variable and returns a dataframe containing these sums.\n",
    "    8. ```pluck_best_variables```: This function takes the two dataframes produced by concatenation of repeated calls to inside_outside and above_below, calls variable_scores on each, and returns all variables with both scores at least 70% of the maximum (for the percentages in the middle 50%) and at most 130% of the minimum (for the percentages above the mean)\n",
    "\n",
    "- [Variable Effects on Prone Accuracy](#Variable-Effects-on-Prone-Accuracy)\n",
    "    1. ```build_racer_pa_distribution```: Given a racer, season, and event as well as dataframes containing similarity data about world cup vs world cup and world cup vs ibu cup race conditions, this function creates a list of accuracies in the following manner. First, it creates a master list in the same manner used by ```build_racer_speed_distribution```, that is to say, by taking multiplicities of the numbers of missed shots over all prior races based on the similarities between the prior race and the current race. Second, the function takes samples of size $n$ (the length of the list) and  calculates the sample average. It then simulates 5 shots and uses the sample average to decide whether each of those shots were misses or not and appends the number of missed shots to the list of predictions. Finally, using this list of predictions, it returns a list containing the racer's name, the mean of the list of prone accuracies, the standard deviation of the list, the 10th, 25th, 50th, 75th, and 90th percentiles, the racer's actual accuracy, and the number of previous races for which the racer had data\n",
    "    2. ```evaluate_variable_impactPA```: This function pulls together ```build_racer_pa_distribution```, ```check_predictions```, ```inside_outside```, and ```above_below```. Given a competition (season and event) and a predictor variable, it calculates the percentage of racers whose actual prone accuracies were within the middle 50% of their distributions and the percentage of racers whose actual prone accuracies were above the mean of their distributions and returns the results in the form of a list.\n",
    "\n",
    "- [Variable Effects on Standing Accuracy](#Variable-Effects-on-Standing-Accuracy)\n",
    "    1. ```build_racer_sa_distribution```: this function is the equivalent of ```build_racer_pa_distribution``` applied to standing rather than prone shooting accuracy\n",
    "    2. ```evaluate_variable_impactSA```: this function is the equivalent of ```evaluate_variable_impactPA``` but using ```build_racer_sa_distribution``` in place of ```build_racer_pa_distribution```\n",
    "\n",
    "\n",
    "- [Variable Effects on Prone Range Times](#Variable-Effects-on-Prone-Range)\n",
    "    1. ```build_racer_pr_distribution```: Given a racer and a competition (season and event) along with similarity dataframes, first builds weighted lists of range times and missed shots. It then creates bootstrap samples from these lists, and fits a linear regression (with missed shots as the predictor variable and range time as the response variable) to estimate the shooting time (intercept) and penalty loop time (slope). Using the same bootstrap sample, the function calculates the average prone shooting percentage, and uses it to simulate a series of five shots. The predicted range time is then calculated as\n",
    "    \n",
    "    *predicted\\_range\\_time* = _shooting time_ + _penalty loop time_ $\\times$ _missed shots_ \n",
    "    \n",
    "    and added to the list of predicted range times. The function returns a list containing the racer's name, the mean of the list of predicted prone range times, the standard deviation of the list, the 10th, 25th, 50th, 75th, and 90th percentiles, the racer's actual prone range time, and the number of previous races for which the racer had data.\n",
    "    2. ```evaluate_variable_impactPR```: This function pulls together ```build_racer_pr_distribution```, ```check_predictions```, ```inside_outside```, and ```above_below```. Given a competition (season and event) and a predictor variable, it calculates the percentage of racers whose actual prone range times were within the middle 50% of their distributions and the percentage of racers whose actual prone range times were above the mean of their distributions and returns the results in the form of a list.\n",
    "\n",
    "\n",
    "- [Variable Effects on Standing Range Times](#Variable-Effects-on-Standing-Range)\n",
    "    1. ```build_racer_sr_distribution```: this function is the equivalent of ```build_racer_pr_distribution``` applied to standing rather than prone range times\n",
    "    2. ```evaluate_variable_impactSR```: this function is the equivalent of ```evaluate_variable_impactPR``` but using ```build_racer_sr_distribution``` in place of ```build_racer_pr_distribution```\n",
    "\n",
    "\n",
    "\\*-value: Here, we use the notation \\*-value to reflect the fact that we use certain functions, for instance ```check_predictions``` and ```above_below``` among others, with the outputs of all of our build distribution functions. The notation \\*-value can thus be interpreted as referring to the racer's actual speed, actual prone shooting accuracy, etc, depending on the context in which the function is being used. Similarly, the notation ```build_racer_*_distribution``` indicates that the function being described can take outputs from ```build_racer_speed_distribution```, ```build_racer_pa_distribution```, etc.\n",
    "\n",
    "Previous Section: [Weighting the Races](#Weighting-the-Races)\n",
    "\n",
    "Next Section: [Pulling it all together](#pulling_together)\n",
    "\n",
    "[Table of Contents](#Table-of-Contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1112', 'CP07'],\n",
       " ['1112', 'CP09'],\n",
       " ['1011', 'CP07'],\n",
       " ['1314', 'CP09'],\n",
       " ['0910', 'CP04'],\n",
       " ['1011', 'CP09'],\n",
       " ['1112', 'CP02'],\n",
       " ['1314', 'CP03'],\n",
       " ['1112', 'CP03'],\n",
       " ['0910', 'CP07']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons = ['0910', '1011', '1112', '1213', '1314']\n",
    "events = ['CP01','CP02','CP03','CP04','CP05','CP06','CP07','CP08','CP09','CH__']\n",
    "\n",
    "chosen_events = []\n",
    "for i in range(10):\n",
    "    redraw = 0\n",
    "    while redraw == 0:\n",
    "        competition = [random.choice(seasons), random.choice(events)]\n",
    "        redraw = 1\n",
    "        if competition in chosen_events:\n",
    "            redraw = 0\n",
    "        if competition[0] == '1314':\n",
    "            if competition[1] in ['CP05','CP06']:\n",
    "                redraw = 0\n",
    "    if competition[0] in ['0910', '1314']:\n",
    "        if competition[1] == 'CH__':\n",
    "            competition[1] = 'OG__'\n",
    "\n",
    "    chosen_events.append(competition)\n",
    "    \n",
    "chosen_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [\"quant_snow\", \"quant_weather\", \"humidity_c\", \"wind_c\", \"snow_temp_c\", \"air_temp_c\", \n",
    "           \"quant_event\", \"quant_year\", \"altitude\", \"total_climb\", \"max_climb\", \"height_diff\", \n",
    "           \"length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Variable Effects on Speed\n",
    "\n",
    "[Isolating the Variable Effects](#Isolating-the-Variable-Effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "adjust_times : Takes a racer and his event speeds over the course of a career, finds the\n",
    "               best fit line through the data, and adjusts early speeds to reflect what \n",
    "               they would be predicted to be if the race were run in the season under \n",
    "               consideration.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "racer : a string containing the name of a biathlete\n",
    "season : a string that codes the season under consideration. It is of the form y1y2 where\n",
    "         y1 is the last two digits of the year in which the season started, and y2 is the \n",
    "         last two digits of the year in which the season ended.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "adjusted_racer : a list containing the racer's speed adjusted for the season under \n",
    "                 consideration\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# To be called inside speed_predictions\n",
    "\n",
    "def adjust_times(racer, season):\n",
    "    \n",
    "    indices = racer.index.tolist()\n",
    "    years = [item.split(':')[1] for item in indices]\n",
    "    years = [''.join(['20',item[2:4]]) for item in years]\n",
    "    years = [float(item) for item in years]\n",
    "    years = np.array(years).reshape(-1,1)\n",
    "    speeds = np.array(racer.tolist()).reshape(-1,1)\n",
    "    \n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(years , speeds)\n",
    "    \n",
    "    coef = linreg.coef_[0][0]\n",
    "    \n",
    "    # creating a time adjusted version of the speeds\n",
    "    \n",
    "    adjusted_racer = racer.copy()\n",
    "    \n",
    "    for i in range(len(racer)):\n",
    "        time_delta = float(season)- years[i][0]\n",
    "        adjusted_racer[i] = adjusted_racer[i] + coef*time_delta\n",
    "        \n",
    "    return adjusted_racer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "build_racer_speed_distribution : takes a racer, season, event, and dataframes containing\n",
    "                                 similarity data about world cup vs world cup and world cup\n",
    "                                 vs ibu cup race conditions, and finds a list of speeds\n",
    "                                 from previous races, where the multiplicity of the speed\n",
    "                                 is determined by the degree of similarity between the race\n",
    "                                 of interest and the race from which the speed was taken. It\n",
    "                                 then returns a list containing the racer's name, the mean of\n",
    "                                 the list of speeds, the standard deviation of the list, the\n",
    "                                 10th, 25th, 50th, 75th, and 90th percentiles, the racer's \n",
    "                                 actual speed, and the number of previous races for which the\n",
    "                                 racer had data\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "racer : a string containing the name of a biathlete\n",
    "season : a string that codes the season under consideration. It is of the form y1y2 where\n",
    "         y1 is the last two digits of the year in which the season started, and y2 is the \n",
    "         last two digits of the year in which the season ended.\n",
    "event : a string that codes the event under consideration. Possible values are 'CP01', \n",
    "        'CP02', 'CP03', 'CP04', 'CP05', 'CP06', 'CP07', 'CP08', 'CP09', 'CH__', 'OG__'\n",
    "wc_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "         between world cup (wc) races in a pairwise fashion. Pairs with a similarity value\n",
    "         of 1 were run under nearly identical conditions, while those with a similarity\n",
    "         value of 0 were run under extremely different conditions\n",
    "ibu_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "          between world cup (wc) races and ibu cup races in a pairwise fashion. \n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "racer_predict : a list of describing the distribution of the weighted prior data\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def build_racer_speed_distribution(racer, season, event, wc_sim, ibu_sim):\n",
    "\n",
    "    col_name = ':'.join(['wc',season, event])\n",
    "    racer_data = absolute_mens_speed.loc[racer, :col_name]\n",
    "    name = racer\n",
    "    actual = float(racer_data[col_name])\n",
    "    short_racer_data = racer_data[2:-1].copy()\n",
    "    short_racer_data.dropna(inplace = True)\n",
    "    predictors = len(short_racer_data)\n",
    "    \n",
    "    year = ''.join(['20',season[2:4]])\n",
    "    short_racer_data = adjust_times(short_racer_data, year)\n",
    "    indices = short_racer_data.index.tolist()\n",
    "\n",
    "    race_weights = []\n",
    "    for index in indices:\n",
    "        split_index = index.split(':')\n",
    "        if split_index[0] == 'wc':\n",
    "            race_weights.append(wc_sim.loc[':'.join([season,event]),\n",
    "                                               ':'.join([split_index[1],split_index[2]])])\n",
    "        else:\n",
    "            race_weights.append(ibu_sim.loc[':'.join([season,event]),\n",
    "                                                ':'.join([split_index[1],split_index[2]])])\n",
    "    race_weights_rounded = [int(round(item,1)*10) for item in race_weights]\n",
    "\n",
    "    race_weights_rounded\n",
    "\n",
    "    # Making the weighted data list\n",
    "    \n",
    "    racer_predict = []\n",
    "\n",
    "    for i in range(len(short_racer_data)): \n",
    "        for j in range(race_weights_rounded[i]):\n",
    "            racer_predict.append(float(short_racer_data[i]))\n",
    "\n",
    "    mean = np.mean(racer_predict)\n",
    "    dev = np.std(racer_predict)\n",
    "    tenth = np.percentile(racer_predict, 10)\n",
    "    q1 = np.percentile(racer_predict, 25)\n",
    "    med = np.median(racer_predict)\n",
    "    q3 = np.percentile(racer_predict, 75)\n",
    "    ninetieth = np.percentile(racer_predict, 90)\n",
    "    \n",
    "    return [name,mean, dev, tenth, q1, med, q3, ninetieth, actual,predictors]\n",
    "\n",
    "\n",
    "            \n",
    "    return racer_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "check_predictions : takes the output of repeated calls to build_racer_*_distribution\n",
    "                    and returns a dataframe indicating which racers fall within the\n",
    "                    middle 50 and 80 percents of their time distributions\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "df : a dataframe that is the output of repeated calls to build_racer_*_distribution\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "checked_predictions : a dataframe with one row for each racer in a given competition\n",
    "                      with columns that indicate whether or not the actual speed of\n",
    "                      the racer during the competition fell within the middle 50%\n",
    "                      or the middle 80% of his speed distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def check_predictions(df):\n",
    "    \n",
    "    checked_predictions = []\n",
    "    for i in range(len(df)):\n",
    "        name = df.loc[i,'name']\n",
    "        predictors = df.loc[i,'predictors']\n",
    "        if df.loc[i,'q1'] <= df.loc[i,'actual'] <= df.loc[i,'q3']:\n",
    "            middle_50 = True\n",
    "        else:\n",
    "            middle_50 = False\n",
    "\n",
    "        if df.loc[i,'tenth'] <= df.loc[i,'actual'] <= df.loc[i,'ninetieth']:\n",
    "            middle_80 = True\n",
    "        else:\n",
    "            middle_80 = False\n",
    "            \n",
    "        checked_predictions.append([name,middle_50, middle_80, predictors])\n",
    "        \n",
    "    checked_predictions = pd.DataFrame(checked_predictions, columns = ['name', 'middle_50',\n",
    "                                                            'middle_80', 'predictors'])\n",
    "    \n",
    "    return checked_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "inside_outside : takes a dataframe output by check_predictions and returns the percentage\n",
    "                 of racers within the middle 50% \n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "df : a dataframe that is the output of a call to check_predictions\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "percent_inside_50 : a float giving the percentage of racers in a given race whose actual time\n",
    "                    was in the middle 50% of their time distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def inside_outside(df):\n",
    "    \n",
    "    inside_50 = 0\n",
    "    outside_50 = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i,'middle_50']:\n",
    "            inside_50 += 1\n",
    "        else:\n",
    "            outside_50 += 1\n",
    "    percent_inside_50 = [inside_50, outside_50, float(inside_50)/(inside_50 + outside_50)*100]\n",
    "\n",
    "\n",
    "    return percent_inside_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "above_below : takes a dataframe produced by repeated calls to build_racer_*_distribution\n",
    "              and determines for each racer whether or not that racer's speed was above\n",
    "              (faster than) the mean of their distribution. The percentage that have\n",
    "              speeds above their means is returned.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "predictions : a dataframe produced by repeated calls to build_racer_*_distribution\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "portion_above : a float telling for what percentage of racers in a race, their actual\n",
    "                speed was faster than the mean of their distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def above_below(predictions):\n",
    "    \n",
    "    count_above = 0\n",
    "    count_below = 0\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions.loc[i,'actual'] >= predictions.loc[i,'mean']:\n",
    "            count_above += 1\n",
    "        else:\n",
    "            count_below += 1\n",
    "            \n",
    "    portion_above = (100.0*count_above)/(count_above + count_below)\n",
    "    \n",
    "    return portion_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "evaluate_variable_impact : pulls together build_racer_speed_distribution, check_predictions,\n",
    "                           inside_outside, and above_below for one predictor and for a single\n",
    "                           event returns the percentage of racers whose actual times were\n",
    "                           within the middle 50% of their distributions and the percentage\n",
    "                           of racers whose actual times were above the mean of their\n",
    "                           distributions.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "competition : a list of the form [season, event], where season is a string that codes \n",
    "              the season under consideration, and event is a string that codes the event\n",
    "              under consideration.\n",
    "variable : a predictor variable. Possible values are \"quant_snow\", \"quant_weather\",\n",
    "           \"humidity_c\", \"wind_c\", \"snow_temp_c\", \"air_temp_c\", \"quant_event\", \n",
    "           \"quant_year\", \"altitude\", \"total_climb\", \"max_climb\", \"height_diff\", and\n",
    "           \"length\"\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "portion_inside : a float giving the percentage of the racers for whom the actual speed\n",
    "                 was in the middle 50% of their speed distribution\n",
    "portion_above : a float giving the percentage of the racers for whom the actual speed\n",
    "                was faster than the mean of their speed distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_variable_impact(competition, variable):\n",
    "    \n",
    "    wc_filename = 'wc_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    ibu_filename = 'ibu_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    \n",
    "    wc_speed_similarities = pd.read_pickle(wc_filename)\n",
    "    ibu_speed_similarities = pd.read_pickle(ibu_filename)\n",
    "    \n",
    "    season = competition[0]\n",
    "    event = competition[1]\n",
    "    \n",
    "    predictions = []\n",
    "    race_code = ':'.join(['wc', season, event])\n",
    "    racer_indices = absolute_mens_speed[race_code].dropna().index.tolist()\n",
    "    for index in racer_indices:\n",
    "        try:\n",
    "            prediction = build_racer_speed_distribution(index,season,event, \n",
    "                                                 wc_speed_similarities, ibu_speed_similarities)\n",
    "            if prediction[-1] > 2:\n",
    "                predictions.append(prediction)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    predictions = pd.DataFrame(predictions, columns = ['name','mean', 'dev', 'tenth', 'q1', \n",
    "                                            'med', 'q3', 'ninetieth', 'actual','predictors'])\n",
    "    \n",
    "    checked_predictions = check_predictions(predictions)\n",
    "    inside_50 = inside_outside(checked_predictions)\n",
    "    \n",
    "    portion_inside = inside_50[2]\n",
    "    \n",
    "    portion_above = above_below(predictions)\n",
    "    \n",
    "    return portion_inside, portion_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percents_in_50 = pd.DataFrame()\n",
    "percents_above_mean = pd.DataFrame()\n",
    "\n",
    "for variable in weights:\n",
    "    for i in range(len(chosen_events)):\n",
    "        inside, above = evaluate_variable_impact(chosen_events[i], variable)\n",
    "        \n",
    "        percents_in_50.loc[variable, i] = np.rint(inside)\n",
    "        percents_above_mean.loc[variable, i] = np.rint(above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "variable_score : takes a dataframe produces by agglomerating the results of repeated\n",
    "                 calls to evaluate_variable_impact and, for each event in question,\n",
    "                 sorts them and assigns one point for the first place variable, two \n",
    "                 for the second place variable, and so on. Returns a dataframe that \n",
    "                 contains the sum of these scores for each variable.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "df : a dataframe that contains either the percents in the middle 50% of the distributions\n",
    "     for a collection of events modeled with each of the available variables, or the \n",
    "     percents above the mean under the same conditions\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "df_scores : a dataframe containing the summed scores over all the events for each variable\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def variable_score(df):\n",
    "    \n",
    "    df_scores = {}\n",
    "\n",
    "    df_scores[df.index.tolist()[0]] = 1\n",
    "\n",
    "    score = 1\n",
    "    compare = 0\n",
    "\n",
    "    for i in range(1,len(df)):\n",
    "        if df[0][i] == df[0][compare]:\n",
    "            df_scores[df.index.tolist()[i]] = score\n",
    "        else:\n",
    "            df_scores[df.index.tolist()[i]] = i+1\n",
    "            score = i+1\n",
    "            compare = i\n",
    "\n",
    "    for j in range(1, df.shape[1]):\n",
    "    \n",
    "        df.sort_values(j,axis = 'rows', inplace = True)\n",
    "        df_scores[df.index.tolist()[0]] = df_scores[df.index.tolist()[0]] + 1\n",
    "\n",
    "        score = 1\n",
    "        compare = 0\n",
    "\n",
    "        for i in range(1,len(df)):\n",
    "            if df[j][i] == df[j][compare]:\n",
    "                df_scores[df.index.tolist()[i]] = df_scores[df.index.tolist()[i]] + score\n",
    "            else:\n",
    "                df_scores[df.index.tolist()[i]] = df_scores[df.index.tolist()[i]] + (i + 1)\n",
    "                score = i + 1\n",
    "                compare = i\n",
    "            \n",
    "    df_scores = pd.DataFrame.from_dict(df_scores, orient='index')\n",
    "        \n",
    "    df_scores.columns = ['score']       \n",
    "            \n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "pluck_best_variables : takes the pair of dataframes produced by concatenation of repeated calls\n",
    "                       to inside_outside and above_below, calls variable_scores on each, \n",
    "                       and returns all variables with both scores at least 70% of the\n",
    "                       maximum (for percent_in_50) and at most 130% of the minimum \n",
    "                       (for perc_above_mean)\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "perc_in_50 : a dataframe produced by concatenation of repeated calls to inside_outside\n",
    "perc_above_mean : a dataframe produced by concatenation of repeated calls to above_below\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "predictors_to_keep : a list of predictor variables that faired well relative to the other \n",
    "                     variables for the current aspect under consideration\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def pluck_best_variables(perc_in_50, perc_above_mean):\n",
    "    \n",
    "    percent_score = variable_score(perc_in_50).sort_values('score',ascending = False)\n",
    "    max_percent = percent_score.iloc[0,0]\n",
    "    \n",
    "    dist_from_50 = abs(perc_above_mean - 50)\n",
    "    distance_score = variable_score(dist_from_50).sort_values('score')\n",
    "    min_distance = distance_score.iloc[0,0]\n",
    "    \n",
    "    overall_score = ((variable_score(dist_from_50)-min_distance) +\n",
    "                        (max_percent-variable_score(perc_in_50))).sort_values('score')\n",
    "    \n",
    "    predictors_to_consider = []\n",
    "    \n",
    "    predictors_to_consider.append(percent_score.index.tolist()[0])\n",
    "    for i in range(1, len(percent_score)):\n",
    "        if percent_score.iloc[i,0] >= 0.70*percent_score.iloc[0,0]:\n",
    "            predictors_to_consider.append(percent_score.index.tolist()[i])\n",
    "\n",
    "    predictors_to_consider.append(distance_score.index.tolist()[0])\n",
    "    for i in range(1, len(distance_score)):\n",
    "        if distance_score.iloc[i,0] <= 1.30*distance_score.iloc[0,0]:\n",
    "            predictors_to_consider.append(distance_score.index.tolist()[i])\n",
    "\n",
    "    predictors_to_consider.append(overall_score.index.tolist()[0])\n",
    "    for i in range(1, len(overall_score)):\n",
    "        if overall_score.iloc[i,0] <= 1.30*overall_score.iloc[0,0]:\n",
    "            predictors_to_consider.append(overall_score.index.tolist()[i])\n",
    "    \n",
    "    predictors = {}\n",
    "    \n",
    "    for pred in predictors_to_consider:\n",
    "        if pred in predictors:\n",
    "            predictors[pred] = predictors[pred] + 1\n",
    "        else:\n",
    "            predictors[pred] = 1\n",
    "    \n",
    "    predictors_to_keep = [item for item in predictors if predictors[item] >= 2]\n",
    "    predictors_to_keep.extend([item for item in predictors if predictors[item] >=3])\n",
    "    \n",
    "    return predictors_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I want to append this to the list of variables that I had before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('best_variables.pickle', 'rb') as handle:\n",
    "    best_variables = pickle.load(handle)\n",
    "\n",
    "# best_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wind_c', 'quant_snow', 'wind_c']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed_variables = pluck_best_variables(percents_in_50, percents_above_mean)\n",
    "best_variables['speed'].extend(speed_variables)\n",
    "\n",
    "speed_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Variable Effects on Prone Accuracy\n",
    "\n",
    "\n",
    "[Isolating the Variable Effects](#Isolating-the-Variable-Effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "build_racer_pa_distribution : for a given racer and a given event and season, produces\n",
    "                              a list of predicted prone shooting accuracies derived by\n",
    "                              sampling from the list of prior data. It then returns a \n",
    "                              list containing the racer's name, the mean of the list of\n",
    "                              speeds, the standard deviation of the list, the 10th, 25th,\n",
    "                              50th, 75th, and 90th percentiles, the racer's actual speed,\n",
    "                              and the number of previous races for which the racer had data\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "racer : a string containing the name of a biathlete\n",
    "season : a string that codes the season under consideration. It is of the form y1y2 where\n",
    "         y1 is the last two digits of the year in which the season started, and y2 is the \n",
    "         last two digits of the year in which the season ended.\n",
    "event : a string that codes the event under consideration. Possible values are 'CP01', \n",
    "        'CP02', 'CP03', 'CP04', 'CP05', 'CP06', 'CP07', 'CP08', 'CP09', 'CH__', 'OG__'\n",
    "wc_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "         between world cup (wc) races in a pairwise fashion. Pairs with a similarity value\n",
    "         of 1 were run under nearly identical conditions, while those with a similarity\n",
    "         value of 0 were run under extremely different conditions\n",
    "ibu_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "          between world cup (wc) races and ibu cup races in a pairwise fashion. \n",
    "\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "racer_predict : a list of describing the distribution of the accuracy predictions \n",
    "                produced using weighted prior data\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def build_racer_pa_distribution(racer, season, event, wc_sim, ibu_sim):\n",
    "\n",
    "    col_name = ':'.join(['wc',season, event])\n",
    "    racer_data = absolute_mens_prone_shooting.loc[racer, :col_name]\n",
    "    name = racer\n",
    "    actual = float(racer_data[col_name])\n",
    "    short_racer_data = racer_data[2:-1].copy()\n",
    "    short_racer_data.dropna(inplace = True)\n",
    "    predictors = len(short_racer_data)\n",
    "    \n",
    "    year = ''.join(['20',season[2:4]])\n",
    "    indices = short_racer_data.index.tolist()\n",
    "\n",
    "    race_weights = []\n",
    "    for index in indices:\n",
    "        try:\n",
    "            split_index = index.split(':')\n",
    "            if split_index[0] == 'wc':\n",
    "                race_weights.append(wc_sim.loc[':'.join([season,event]),\n",
    "                                               ':'.join([split_index[1],split_index[2]])])\n",
    "            else:\n",
    "                race_weights.append(ibu_sim.loc[':'.join([season,event]),\n",
    "                                                ':'.join([split_index[1],split_index[2]])])\n",
    "        except:\n",
    "            race_weights.append(0.0)\n",
    "    race_weights_rounded = [int(round(item,1)*10) for item in race_weights]\n",
    "\n",
    "    race_weights_rounded\n",
    "\n",
    "    # Making the weighted data list\n",
    "    \n",
    "    racer_accuracy = []\n",
    "    racer_predict = []\n",
    "\n",
    "    for i in range(len(short_racer_data)): \n",
    "        for j in range(race_weights_rounded[i]):\n",
    "            racer_accuracy.append(float(short_racer_data[i]))\n",
    "                        \n",
    "    for k in range(len(racer_accuracy)): \n",
    "        shooting_sample = np.random.choice(racer_accuracy, len(racer_accuracy), \n",
    "                                                       replace = True)\n",
    "        pred_percent = np.mean(shooting_sample)/5\n",
    "        shooting = np.random.sample(5)\n",
    "        count = 0\n",
    "        for m in range(5):\n",
    "            if shooting[m] < pred_percent:\n",
    "                count += 1\n",
    "        racer_predict.append(count)\n",
    "\n",
    "    mean = np.mean(racer_predict)\n",
    "    dev = np.std(racer_predict)\n",
    "    tenth = np.percentile(racer_predict, 10)\n",
    "    q1 = np.percentile(racer_predict, 25)\n",
    "    med = np.median(racer_predict)\n",
    "    q3 = np.percentile(racer_predict, 75)\n",
    "    ninetieth = np.percentile(racer_predict, 90)\n",
    "    \n",
    "    return [name,mean, dev, tenth, q1, med, q3, ninetieth, actual,predictors]\n",
    "\n",
    "\n",
    "            \n",
    "    return racer_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "evaluate_variable_impactPA : pulls together build_racer_pa_distribution, check_predictions,\n",
    "                             inside_outside, and above_below for all predictors for a given\n",
    "                             event returns the percentage of racers whose actual times were\n",
    "                             within the middle 50% of their distributions and the percentage\n",
    "                             of racers whose actual times were above the mean of their\n",
    "                             distributions.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "competition : a list of the form [season, event], where season is a string that codes \n",
    "              the season under consideration, and event is a string that codes the event\n",
    "              under consideration.\n",
    "variable : a predictor variable. Possible values are \"quant_snow\", \"quant_weather\",\n",
    "           \"humidity_c\", \"wind_c\", \"snow_temp_c\", \"air_temp_c\", \"quant_event\", \n",
    "           \"quant_year\", \"altitude\", \"total_climb\", \"max_climb\", \"height_diff\", and\n",
    "           \"length\"\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "portion_inside : a float giving the percentage of the racers for whom the actual speed\n",
    "                 was in the middle 50% of their speed distribution\n",
    "portion_above : a float giving the percentage of the racers for whom the actual speed\n",
    "                was faster than the mean of their speed distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "def evaluate_variable_impactPA(competition, variable):\n",
    "    \n",
    "    wc_filename = 'wc_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    ibu_filename = 'ibu_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    \n",
    "    wc_similarities = pd.read_pickle(wc_filename)\n",
    "    ibu_similarities = pd.read_pickle(ibu_filename)\n",
    "    \n",
    "    season = competition[0]\n",
    "    event = competition[1]\n",
    "    \n",
    "    predictions = []\n",
    "    race_code = ':'.join(['wc', season, event])\n",
    "    racer_indices = absolute_mens_prone_shooting[race_code].dropna().index.tolist()\n",
    "    for index in racer_indices:\n",
    "        try:\n",
    "            prediction = build_racer_pa_distribution(index,season,event, \n",
    "                                                        wc_similarities, ibu_similarities)\n",
    "            if prediction[-1] > 2:\n",
    "                predictions.append(prediction)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    predictions = pd.DataFrame(predictions, columns = ['name','mean', 'dev', 'tenth', 'q1',\n",
    "                                            'med', 'q3', 'ninetieth', 'actual','predictors'])\n",
    "    \n",
    "    checked_predictions = check_predictions(predictions)\n",
    "    inside_50 = inside_outside(checked_predictions)\n",
    "    \n",
    "    portion_inside = inside_50[2]\n",
    "    \n",
    "    portion_above = above_below(predictions)\n",
    "    \n",
    "    return portion_inside, portion_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "percents_in_50 = pd.DataFrame()\n",
    "percents_above_mean = pd.DataFrame()\n",
    "\n",
    "for variable in weights:\n",
    "    for i in range(len(chosen_events)):\n",
    "\n",
    "        inside, above = evaluate_variable_impactPA(chosen_events[i], variable)\n",
    "        \n",
    "        percents_in_50.loc[variable, i] = np.rint(inside)\n",
    "        percents_above_mean.loc[variable, i] = np.rint(above)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quant_year', 'quant_weather']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prone_acc_variables = pluck_best_variables(percents_in_50, percents_above_mean)\n",
    "\n",
    "best_variables['prone_acc'].extend(prone_acc_variables)\n",
    "prone_acc_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Variable Effects on Standing Accuracy\n",
    "\n",
    "[Isolating the Variable Effects](#Isolating-the-Variable-Effects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "build_racer_sa_distribution : for a given racer and a given event and season, produces\n",
    "                              a list of predicted standing shooting accuracies derived by\n",
    "                              sampling from the list of prior data. It then returns a \n",
    "                              list containing the racer's name, the mean of the list of\n",
    "                              speeds, the standard deviation of the list, the 10th, 25th,\n",
    "                              50th, 75th, and 90th percentiles, the racer's actual speed,\n",
    "                              and the number of previous races for which the racer had data\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "racer : a string containing the name of a biathlete\n",
    "season : a string that codes the season under consideration. It is of the form y1y2 where\n",
    "         y1 is the last two digits of the year in which the season started, and y2 is the \n",
    "         last two digits of the year in which the season ended.\n",
    "event : a string that codes the event under consideration. Possible values are 'CP01', \n",
    "        'CP02', 'CP03', 'CP04', 'CP05', 'CP06', 'CP07', 'CP08', 'CP09', 'CH__', 'OG__'\n",
    "wc_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "         between world cup (wc) races in a pairwise fashion. Pairs with a similarity value\n",
    "         of 1 were run under nearly identical conditions, while those with a similarity\n",
    "         value of 0 were run under extremely different conditions\n",
    "ibu_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "          between world cup (wc) races and ibu cup races in a pairwise fashion. \n",
    "\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "racer_predict : a list of describing the distribution of the accuracy predictions \n",
    "                produced using weighted prior data\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def build_racer_sa_distribution(racer, season, event, wc_sim, ibu_sim):\n",
    "\n",
    "    col_name = ':'.join(['wc',season, event])\n",
    "    racer_data = absolute_mens_standing_shooting.loc[racer, :col_name]\n",
    "    name = racer\n",
    "    actual = float(racer_data[col_name])\n",
    "    short_racer_data = racer_data[2:-1].copy()\n",
    "    short_racer_data.dropna(inplace = True)\n",
    "    predictors = len(short_racer_data)\n",
    "    \n",
    "    year = ''.join(['20',season[2:4]])\n",
    "    indices = short_racer_data.index.tolist()\n",
    "\n",
    "    race_weights = []\n",
    "    for index in indices:\n",
    "        split_index = index.split(':')\n",
    "        try:\n",
    "            if split_index[0] == 'wc':\n",
    "                race_weights.append(wc_sim.loc[':'.join([season,event]),\n",
    "                                                   ':'.join([split_index[1],split_index[2]])])\n",
    "            else:\n",
    "                race_weights.append(ibu_sim.loc[':'.join([season,event]),\n",
    "                                                    ':'.join([split_index[1],split_index[2]])])\n",
    "        except:\n",
    "            race_weights.append(0.0)\n",
    "    race_weights_rounded = [int(round(item,1)*10) for item in race_weights]\n",
    "\n",
    "    race_weights_rounded\n",
    "\n",
    "    # Making the weighted data list\n",
    "    \n",
    "    racer_accuracy = []\n",
    "    racer_predict = []\n",
    "\n",
    "    for i in range(len(short_racer_data)): \n",
    "        for j in range(race_weights_rounded[i]):\n",
    "            racer_accuracy.append(float(short_racer_data[i]))\n",
    "                        \n",
    "    for k in range(len(racer_accuracy)): \n",
    "        shooting_sample = np.random.choice(racer_accuracy, len(racer_accuracy), replace = True)\n",
    "        pred_percent = np.mean(shooting_sample)/5\n",
    "        shooting = np.random.sample(5)\n",
    "        count = 0\n",
    "        for m in range(5):\n",
    "            if shooting[m] < pred_percent:\n",
    "                count += 1\n",
    "        racer_predict.append(count)\n",
    "\n",
    "    mean = np.mean(racer_predict)\n",
    "    dev = np.std(racer_predict)\n",
    "    tenth = np.percentile(racer_predict, 10)\n",
    "    q1 = np.percentile(racer_predict, 25)\n",
    "    med = np.median(racer_predict)\n",
    "    q3 = np.percentile(racer_predict, 75)\n",
    "    ninetieth = np.percentile(racer_predict, 90)\n",
    "    \n",
    "    return [name,mean, dev, tenth, q1, med, q3, ninetieth, actual,predictors]\n",
    "\n",
    "\n",
    "            \n",
    "    return racer_predict, racer_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "evaluate_variable_impactSA : pulls together build_racer_sa_distribution, check_predictions,\n",
    "                             inside_outside, and above_below for all predictors for a given\n",
    "                             event returns the percentage of racers whose actual times were\n",
    "                             within the middle 50% of their distributions and the percentage\n",
    "                             of racers whose actual times were above the mean of their\n",
    "                             distributions.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "competition : a list of the form [season, event], where season is a string that codes \n",
    "              the season under consideration, and event is a string that codes the event\n",
    "              under consideration.\n",
    "variable : a predictor variable. Possible values are \"quant_snow\", \"quant_weather\",\n",
    "           \"humidity_c\", \"wind_c\", \"snow_temp_c\", \"air_temp_c\", \"quant_event\", \n",
    "           \"quant_year\", \"altitude\", \"total_climb\", \"max_climb\", \"height_diff\", and\n",
    "           \"length\"\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "portion_inside : a float giving the percentage of the racers for whom the actual speed\n",
    "                 was in the middle 50% of their speed distribution\n",
    "portion_above : a float giving the percentage of the racers for whom the actual speed\n",
    "                was faster than the mean of their speed distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "def evaluate_variable_impactSA(competition, variable):\n",
    "    \n",
    "    wc_filename = 'wc_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    ibu_filename = 'ibu_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    \n",
    "    wc_speed_similarities = pd.read_pickle(wc_filename)\n",
    "    ibu_speed_similarities = pd.read_pickle(ibu_filename)\n",
    "    \n",
    "    season = competition[0]\n",
    "    event = competition[1]\n",
    "\n",
    "\n",
    "    predictions = []\n",
    "    race_code = ':'.join(['wc',season, event])\n",
    "    racer_indices = absolute_mens_standing_shooting[race_code].dropna().index.tolist()\n",
    "    for index in racer_indices:\n",
    "        try:\n",
    "            prediction = build_racer_sa_distribution(index,season,event, \n",
    "                                              wc_speed_similarities, ibu_speed_similarities)\n",
    "            if prediction[-1] > 2:\n",
    "                predictions.append(prediction)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    predictions = pd.DataFrame(predictions, columns = ['name','mean', 'dev', 'tenth', 'q1',\n",
    "                                            'med', 'q3', 'ninetieth', 'actual','predictors'])\n",
    "    \n",
    "    checked_predictions = check_predictions(predictions)\n",
    "    inside_50 = inside_outside(checked_predictions)\n",
    "    \n",
    "    portion_inside = inside_50[2]\n",
    "    \n",
    "    portion_above = above_below(predictions)\n",
    "    \n",
    "    return portion_inside, portion_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "percents_in_50 = pd.DataFrame()\n",
    "percents_above_mean = pd.DataFrame()\n",
    "\n",
    "for variable in weights:\n",
    "    for i in range(len(chosen_events)):\n",
    "\n",
    "        inside, above = evaluate_variable_impactSA(chosen_events[i], variable)\n",
    "        \n",
    "        percents_in_50.loc[variable, i] = np.rint(inside)\n",
    "        percents_above_mean.loc[variable, i] = np.rint(above)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['altitude', 'wind_c', 'altitude']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standing_acc_variables = pluck_best_variables(percents_in_50, percents_above_mean)\n",
    "\n",
    "best_variables['standing_acc'].extend(standing_acc_variables)\n",
    "standing_acc_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Variable Effects on Prone Range\n",
    "\n",
    "So, I think that what I want to do here is to \n",
    "1. randomly sample the weighted racer data\n",
    "2. fit a best fit linear regression to the sample\n",
    "3. take the mean of the sampled shooting data to predict the number of missed shots\n",
    "4. use the predicted intercept and coeff to calculate the predicted range time.\n",
    "\n",
    "[Isolating the Variable Effects](#Isolating-the-Variable-Effects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "build_racer_pr_distribution : for a given racer and a given event and season, produces\n",
    "                              a list of predicted prone shooting accuracies and associated\n",
    "                              range times derived by using linear regression and \n",
    "                              sampling from the list of prior data. It then returns a \n",
    "                              list containing the racer's name, the mean of the list of\n",
    "                              speeds, the standard deviation of the list, the 10th, 25th,\n",
    "                              50th, 75th, and 90th percentiles, the racer's actual speed,\n",
    "                              and the number of previous races for which the racer had data\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "racer : a string containing the name of a biathlete\n",
    "season : a string that codes the season under consideration. It is of the form y1y2 where\n",
    "         y1 is the last two digits of the year in which the season started, and y2 is the \n",
    "         last two digits of the year in which the season ended.\n",
    "event : a string that codes the event under consideration. Possible values are 'CP01', \n",
    "        'CP02', 'CP03', 'CP04', 'CP05', 'CP06', 'CP07', 'CP08', 'CP09', 'CH__', 'OG__'\n",
    "wc_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "         between world cup (wc) races in a pairwise fashion. Pairs with a similarity value\n",
    "         of 1 were run under nearly identical conditions, while those with a similarity\n",
    "         value of 0 were run under extremely different conditions\n",
    "ibu_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "          between world cup (wc) races and ibu cup races in a pairwise fashion. \n",
    "\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "name : the name of the racer\n",
    "mean : the mean of the distribution of predicted range times\n",
    "dev : the standard deviation of the prediction of predicted range times\n",
    "tenth : the 10th percentile of the prediction of predicted range times\n",
    "q1 : the 25th percentile of the prediction of predicted range times\n",
    "med : the median of the prediction of predicted range times\n",
    "q3 : the 75th percentile of the prediction of predicted range times\n",
    "ninetieth : the 90th percentile of the prediction of predicted range times\n",
    "actual : the racer's actual prone range time\n",
    "predictors : the number of prior sprint races in which the racer has participated\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def build_racer_pr_distribution(racer, season, event, wc_sim, ibu_sim):\n",
    "\n",
    "    col_name = ':'.join(['wc',season, event])\n",
    "    racer_time_data = absolute_mens_prone_range.loc[racer, :col_name]\n",
    "    racer_shot_data = absolute_mens_prone_shooting.loc[racer, :col_name]\n",
    "    name = racer\n",
    "    actual = float(racer_time_data[col_name])\n",
    "    short_racer_time_data = racer_time_data[2:-1].copy()\n",
    "    short_racer_shot_data = racer_shot_data[2:-1].copy()\n",
    "    short_racer_time_data.dropna(inplace = True)\n",
    "    short_racer_shot_data.dropna(inplace = True)\n",
    "    predictors = len(short_racer_shot_data)\n",
    "    \n",
    "    year = ''.join(['20',season[2:4]])\n",
    "    indices = short_racer_shot_data.index.tolist()\n",
    "\n",
    "    race_weights = []\n",
    "    for index in indices:\n",
    "        split_index = index.split(':')\n",
    "        if split_index[0] == 'wc':\n",
    "            race_weights.append(wc_sim.loc[':'.join([season,event]),\n",
    "                                           ':'.join([split_index[1],split_index[2]])])\n",
    "        else:\n",
    "            race_weights.append(ibu_sim.loc[':'.join([season,event]),\n",
    "                                            ':'.join([split_index[1],split_index[2]])])\n",
    "    race_weights_rounded = [int(round(item,1)*10) for item in race_weights]\n",
    "\n",
    "    race_weights_rounded\n",
    "\n",
    "    # Making the weighted data list\n",
    "    \n",
    "    racer_shot = []\n",
    "    racer_time = []\n",
    "    racer_predict = []\n",
    "\n",
    "    for i in range(len(short_racer_shot_data)): \n",
    "        for j in range(race_weights_rounded[i]):\n",
    "            racer_shot.append(float(short_racer_shot_data[i]))\n",
    "            racer_time.append(float(short_racer_time_data[i]))\n",
    "                        \n",
    "    for k in range(100): \n",
    "        index_sample = np.random.choice(range(len(racer_shot)), len(racer_shot),\n",
    "                                                replace = True)\n",
    "        racer_shot_sample = [racer_shot[i] for i in index_sample]\n",
    "        racer_time_sample = [racer_time[i] for i in index_sample]\n",
    "        \n",
    "        accuracy = np.mean(racer_shot_sample)/5\n",
    "        \n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(np.array(racer_shot_sample).reshape(-1,1), \n",
    "                   np.array(racer_time_sample).reshape(-1,1))\n",
    "        loop = linreg.coef_\n",
    "        shot_time = linreg.intercept_\n",
    "        \n",
    "        shooting = np.random.sample(5)\n",
    "        count = 0\n",
    "        for m in range(5):\n",
    "            if shooting[m] < accuracy:\n",
    "                count += 1\n",
    "        range_time = shot_time + count*loop\n",
    "        racer_predict.append(range_time)\n",
    "                                        \n",
    "    mean = np.mean(racer_predict)\n",
    "    dev = np.std(racer_predict)\n",
    "    tenth = np.percentile(racer_predict, 10)\n",
    "    q1 = np.percentile(racer_predict, 25)\n",
    "    med = np.median(racer_predict)\n",
    "    q3 = np.percentile(racer_predict, 75)\n",
    "    ninetieth = np.percentile(racer_predict, 90)\n",
    "    \n",
    "    return [name,mean, dev, tenth, q1, med, q3, ninetieth, actual,predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "evaluate_variable_impactPR : pulls together build_racer_pr_distribution, check_predictions,\n",
    "                             inside_outside, and above_below for all predictors for a given\n",
    "                             event returns the percentage of racers whose actual times were\n",
    "                             within the middle 50% of their distributions and the percentage\n",
    "                             of racers whose actual times were above the mean of their\n",
    "                             distributions.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "competition : a list of the form [season, event], where season is a string that codes \n",
    "              the season under consideration, and event is a string that codes the event\n",
    "              under consideration.\n",
    "variable : a predictor variable. Possible values are \"quant_snow\", \"quant_weather\",\n",
    "           \"humidity_c\", \"wind_c\", \"snow_temp_c\", \"air_temp_c\", \"quant_event\", \n",
    "           \"quant_year\", \"altitude\", \"total_climb\", \"max_climb\", \"height_diff\", and\n",
    "           \"length\"\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "portion_inside : a float giving the percentage of the racers for whom the actual speed\n",
    "                 was in the middle 50% of their speed distribution\n",
    "portion_above : a float giving the percentage of the racers for whom the actual speed\n",
    "                was faster than the mean of their speed distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_variable_impactPR(competition, variable):\n",
    "    \n",
    "    wc_filename = 'wc_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    ibu_filename = 'ibu_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    \n",
    "    wc_speed_similarities = pd.read_pickle(wc_filename)\n",
    "    ibu_speed_similarities = pd.read_pickle(ibu_filename)\n",
    "    \n",
    "    season = competition[0]\n",
    "    event = competition[1]\n",
    "    \n",
    "    predictions = []\n",
    "    race_code = ':'.join(['wc',season, event])\n",
    "    racer_indices = absolute_mens_prone_range[race_code].dropna().index.tolist()\n",
    "    for index in racer_indices:\n",
    "        try:\n",
    "            prediction = build_racer_pr_distribution(index,season,event, \n",
    "                                                 wc_speed_similarities, ibu_speed_similarities)\n",
    "            if prediction[-1] > 2:\n",
    "                predictions.append(prediction)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    predictions = pd.DataFrame(predictions, columns = ['name','mean', 'dev', 'tenth', 'q1',\n",
    "                                            'med', 'q3', 'ninetieth', 'actual','predictors'])\n",
    "    \n",
    "    checked_predictions = check_predictions(predictions)\n",
    "    inside_50 = inside_outside(checked_predictions)\n",
    "    \n",
    "    portion_inside = inside_50[2]\n",
    "    \n",
    "    portion_above = above_below(predictions)\n",
    "    \n",
    "    return portion_inside, portion_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "percents_in_50 = pd.DataFrame()\n",
    "percents_above_mean = pd.DataFrame()\n",
    "\n",
    "for variable in weights:\n",
    "    for i in range(len(chosen_events)):\n",
    "        \n",
    "         \n",
    "        inside, above = evaluate_variable_impactPR(chosen_events[i], variable)\n",
    "        \n",
    "        percents_in_50.loc[variable, i] = np.rint(inside)\n",
    "        percents_above_mean.loc[variable, i] = np.rint(above)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['altitude', 'quant_event', 'quant_event']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prone_range_variables = pluck_best_variables(percents_in_50, percents_above_mean)\n",
    "\n",
    "best_variables['prone_range'].extend(prone_range_variables)\n",
    "prone_range_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Variable Effects on Standing Range\n",
    "\n",
    "[Isolating the Variable Effects](#Isolating-the-Variable-Effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "build_racer_sr_distribution : for a given racer and a given event and season, produces\n",
    "                              a list of predicted standing shooting accuracies and \n",
    "                              associated range times derived by using linear regression\n",
    "                              and  sampling from the list of prior data. It then returns a \n",
    "                              list containing the racer's name, the mean of the list of\n",
    "                              speeds, the standard deviation of the list, the 10th, 25th,\n",
    "                              50th, 75th, and 90th percentiles, the racer's actual speed,\n",
    "                              and the number of previous races for which the racer had data\n",
    "\n",
    "\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "racer : a string containing the name of a biathlete\n",
    "season : a string that codes the season under consideration. It is of the form y1y2 where\n",
    "         y1 is the last two digits of the year in which the season started, and y2 is the \n",
    "         last two digits of the year in which the season ended.\n",
    "event : a string that codes the event under consideration. Possible values are 'CP01', \n",
    "        'CP02', 'CP03', 'CP04', 'CP05', 'CP06', 'CP07', 'CP08', 'CP09', 'CH__', 'OG__'\n",
    "wc_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "         between world cup (wc) races in a pairwise fashion. Pairs with a similarity value\n",
    "         of 1 were run under nearly identical conditions, while those with a similarity\n",
    "         value of 0 were run under extremely different conditions\n",
    "ibu_sim : a dataframe containing values between 0 and 1 which codes the degree of similarity \n",
    "          between world cup (wc) races and ibu cup races in a pairwise fashion. \n",
    "\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "name : the name of the racer\n",
    "mean : the mean of the distribution of predicted range times\n",
    "dev : the standard deviation of the prediction of predicted range times\n",
    "tenth : the 10th percentile of the prediction of predicted range times\n",
    "q1 : the 25th percentile of the prediction of predicted range times\n",
    "med : the median of the prediction of predicted range times\n",
    "q3 : the 75th percentile of the prediction of predicted range times\n",
    "ninetieth : the 90th percentile of the prediction of predicted range times\n",
    "actual : the racer's actual standing range time\n",
    "predictors : the number of prior sprint races in which the racer has participated\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def build_racer_sr_distribution(racer, season, event, wc_sim, ibu_sim):\n",
    "\n",
    "    col_name = ':'.join(['wc',season, event])\n",
    "    racer_time_data = absolute_mens_standing_range.loc[racer, :col_name]\n",
    "    racer_shot_data = absolute_mens_standing_shooting.loc[racer, :col_name]\n",
    "    name = racer\n",
    "    actual = float(racer_time_data[col_name])\n",
    "    short_racer_time_data = racer_time_data[2:-1].copy()\n",
    "    short_racer_shot_data = racer_shot_data[2:-1].copy()\n",
    "    short_racer_time_data.dropna(inplace = True)\n",
    "    short_racer_shot_data.dropna(inplace = True)\n",
    "    predictors = len(short_racer_shot_data)\n",
    "    \n",
    "    year = ''.join(['20',season[2:4]])\n",
    "    indices = short_racer_shot_data.index.tolist()\n",
    "\n",
    "    race_weights = []\n",
    "    for index in indices:\n",
    "        split_index = index.split(':')\n",
    "        try:\n",
    "            if split_index[0] == 'wc':\n",
    "                race_weights.append(wc_sim.loc[':'.join([season,event]),\n",
    "                                               ':'.join([split_index[1],split_index[2]])])\n",
    "            else:\n",
    "                race_weights.append(ibu_sim.loc[':'.join([season,event]),\n",
    "                                                ':'.join([split_index[1],split_index[2]])])\n",
    "        except:\n",
    "            race_weights.append(0.0)\n",
    "    race_weights_rounded = [int(round(item,1)*10) for item in race_weights]\n",
    "\n",
    "    race_weights_rounded\n",
    "\n",
    "    # Making the weighted data list\n",
    "    \n",
    "    racer_shot = []\n",
    "    racer_time = []\n",
    "    racer_predict = []\n",
    "\n",
    "    for i in range(len(short_racer_shot_data)): \n",
    "        for j in range(race_weights_rounded[i]):\n",
    "            racer_shot.append(float(short_racer_shot_data[i]))\n",
    "            racer_time.append(float(short_racer_time_data[i]))\n",
    "                                    \n",
    "    for k in range(100): \n",
    "        index_sample = np.random.choice(range(len(racer_shot)), len(racer_shot), \n",
    "                                        replace = True)\n",
    "        racer_shot_sample = [racer_shot[i] for i in index_sample]\n",
    "        racer_time_sample = [racer_time[i] for i in index_sample]\n",
    "        \n",
    "        accuracy = np.mean(racer_shot_sample)/5\n",
    "        \n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(np.array(racer_shot_sample).reshape(-1,1), \n",
    "                               np.array(racer_time_sample).reshape(-1,1))\n",
    "        loop = linreg.coef_\n",
    "        shot_time = linreg.intercept_\n",
    "        \n",
    "        shooting = np.random.sample(5)\n",
    "        count = 0\n",
    "        for m in range(5):\n",
    "            if shooting[m] < accuracy:\n",
    "                count += 1\n",
    "        range_time = shot_time + count*loop\n",
    "        racer_predict.append(range_time)\n",
    "                                        \n",
    "    mean = np.mean(racer_predict)\n",
    "    dev = np.std(racer_predict)\n",
    "    tenth = np.percentile(racer_predict, 10)\n",
    "    q1 = np.percentile(racer_predict, 25)\n",
    "    med = np.median(racer_predict)\n",
    "    q3 = np.percentile(racer_predict, 75)\n",
    "    ninetieth = np.percentile(racer_predict, 90)\n",
    "    \n",
    "    return [name,mean, dev, tenth, q1, med, q3, ninetieth, actual,predictors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "evaluate_variable_impactSR : pulls together build_racer_sr_distribution, check_predictions,\n",
    "                             inside_outside, and above_below for all predictors for a given\n",
    "                             event returns the percentage of racers whose actual times were\n",
    "                             within the middle 50% of their distributions and the percentage\n",
    "                             of racers whose actual times were above the mean of their\n",
    "                             distributions.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "competition : a list of the form [season, event], where season is a string that codes \n",
    "              the season under consideration, and event is a string that codes the event\n",
    "              under consideration.\n",
    "variable : a predictor variable. Possible values are \"quant_snow\", \"quant_weather\",\n",
    "           \"humidity_c\", \"wind_c\", \"snow_temp_c\", \"air_temp_c\", \"quant_event\", \n",
    "           \"quant_year\", \"altitude\", \"total_climb\", \"max_climb\", \"height_diff\", and\n",
    "           \"length\"\n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "portion_inside : a float giving the percentage of the racers for whom the actual speed\n",
    "                 was in the middle 50% of their speed distribution\n",
    "portion_above : a float giving the percentage of the racers for whom the actual speed\n",
    "                was faster than the mean of their speed distribution\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate_variable_impactSR(competition, variable):\n",
    "    \n",
    "    wc_filename = 'wc_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    ibu_filename = 'ibu_%(variable)s_similarities.pkl' %{'variable' :variable}\n",
    "    \n",
    "    wc_speed_similarities = pd.read_pickle(wc_filename)\n",
    "    ibu_speed_similarities = pd.read_pickle(ibu_filename)\n",
    "    \n",
    "    season = competition[0]\n",
    "    event = competition[1]\n",
    "    \n",
    "    predictions = []\n",
    "    race_code = ':'.join(['wc', season, event])\n",
    "    racer_indices = absolute_mens_standing_range[race_code].dropna().index.tolist()\n",
    "    for index in racer_indices:\n",
    "        try:\n",
    "            prediction = build_racer_sr_distribution(index, season,event, \n",
    "                                                 wc_speed_similarities, ibu_speed_similarities)\n",
    "            if prediction[-1] > 2:\n",
    "                predictions.append(prediction)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    predictions = pd.DataFrame(predictions, columns = ['name','mean', 'dev', 'tenth', 'q1',\n",
    "                                           'med', 'q3', 'ninetieth', 'actual','predictors'])\n",
    "    \n",
    "    checked_predictions = check_predictions(predictions)\n",
    "    inside_50 = inside_outside(checked_predictions)\n",
    "    \n",
    "    portion_inside = inside_50[2]\n",
    "    \n",
    "    portion_above = above_below(predictions)\n",
    "    \n",
    "    return portion_inside, portion_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percents_in_50 = pd.DataFrame()\n",
    "percents_above_mean = pd.DataFrame()\n",
    "\n",
    "for variable in weights:\n",
    "    for i in range(len(chosen_events)):\n",
    "         \n",
    "        inside, above = evaluate_variable_impactSR(chosen_events[i], variable)\n",
    "        \n",
    "        percents_in_50.loc[variable, i] = np.rint(inside)\n",
    "        percents_above_mean.loc[variable, i] = np.rint(above)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quant_weather', 'quant_weather']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standing_range_variables = pluck_best_variables(percents_in_50, percents_above_mean)\n",
    "\n",
    "best_variables['prone_range'].extend(standing_range_variables)\n",
    "standing_range_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"pulling_together\"></a>\n",
    "# Putting it all together\n",
    "\n",
    "At this point, we have a dictionary of which has as its index the various pieces of the biathlon sprint time (speed, prone accuracy, standing accuracy, prone range time, standing range time, prone loop time, and standing loop time), and which has as entry for each index value a list of predictor variables that did well (relatively speaking) either in terms of their predictive powers (this notebook) or in terms of their degree of correlation (the previous notebook). These variables will form the basis of the models that we will build in the next notebooks, but before they can be used, there is a certain amount of housekeeping that needs to be done. First, we use a dictionary to make the code that we are using for each variable consistant. Second, we combine the variables for prone range time and prone loop time as well as for standing range time and standing loop time. Finally, we use <a href = \"#count_frequency\">```count_frequency```</a> (which simply counts the number of times each value appears in a list) to count the entries in the list associated with each aspect, and we save only those aspects that appear at least twice. (That is to say, we save only those variables that have both strong predictive power and relatively high correlation values.) The resulting dictionary is then stored as a pickle file in order to be accessible to later notebooks.\n",
    "\n",
    "Previous Section: [Isolating Variable Effects](#isolating_variable_effects)\n",
    "\n",
    "<a href = \"#toc\">Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_variables1 = best_variables.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translations = {'Quant Weather' : 'quant_weather', 'Quant Snow' : 'quant_snow', \n",
    "                'Snow Temp' : 'snow_temp', 'Air Temp' : 'air_temp', \n",
    "                'Quant Event' : 'quant_event', 'Quant Year' : 'quant_year', 'Wind' : 'wind_c',\n",
    "                'Max Climb' : 'max_climb'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in ['prone_acc', 'prone_loop','prone_range','speed','standing_acc','standing_loop','standing_range']:\n",
    "    variables = best_variables[i]\n",
    "    for j in range(len(variables)):\n",
    "        if variables[j] in translations:\n",
    "            variables[j] = translations[variables[j]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combining range and loop variables\n",
    "\n",
    "best_variables['prone_range'].extend(best_variables['prone_loop'])\n",
    "best_variables['standing_range'].extend(best_variables['standing_loop'])\n",
    "\n",
    "if 'prone_loop' in best_variables:\n",
    "    del best_variables['prone_loop']\n",
    "    \n",
    "if 'standing_loop' in best_variables:\n",
    "    del best_variables['standing_loop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "\n",
    "count_frequency : takes a list containing (possibly) repeating values and returns a \n",
    "                  list of the distinct values in that list, together with their \n",
    "                  frequencies\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "data_list : a list with (possibly) repeating values \n",
    "\n",
    "Returns\n",
    "-------\n",
    "\n",
    "frequencies : a list of distinct values in data_list together with the frequency with\n",
    "              which each of them occured\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\"\"\"\n",
    "\n",
    "def count_frequency(data_list):\n",
    "    \n",
    "    frequencies = {}\n",
    "    for i in range(len(data_list)):\n",
    "        if data_list[i] in frequencies:\n",
    "            frequencies[data_list[i]] = frequencies[data_list[i]] + 1\n",
    "        else:\n",
    "            frequencies[data_list[i]] = 1\n",
    "            \n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prone_acc': ['quant_weather'],\n",
       " 'prone_range': ['quant_weather', 'quant_snow', 'quant_event'],\n",
       " 'speed': ['wind_c', 'quant_snow'],\n",
       " 'standing_acc': ['altitude', 'wind_c'],\n",
       " 'standing_range': ['quant_weather', 'quant_snow']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ['prone_acc','prone_range','speed','standing_range','standing_acc']:\n",
    "    frequencies = count_frequency(best_variables[i])\n",
    "    var_to_keep = [item for item in frequencies if frequencies[item]>=2]\n",
    "    best_variables[i] = var_to_keep\n",
    "    \n",
    "best_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle the dictionary of the best variables\n",
    "\n",
    "with open('best_variables1.pickle', 'wb') as handle:\n",
    "    pickle.dump(best_variables, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
